{"cells": [{"cell_type": "markdown", "metadata": {"_uuid": "281275d20b3c5f659236d880031e3da4b7977e06"}, "source": ["# Import Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ebb7ec8cdfe9b840f5b5ba1524f4e892994e46cc"}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import os\n", "\n", "import gc"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"_uuid": "713132d2f045501c82e42290550d356ae0727c35"}, "outputs": [], "source": ["DATA_ROOT = '../input/'\n", "ORIGINAL_DATA_FOLDER = os.path.join(DATA_ROOT, 'movie-review-sentiment-analysis-kernels-only')\n", "TMP_DATA_FOLDER = os.path.join(DATA_ROOT, 'kaggle_review_sentiment_tmp_data')"]}, {"cell_type": "code", "execution_count": 34, "metadata": {"_uuid": "98fd884ce5265326d434498bda1f5bb813f24e95"}, "outputs": [], "source": ["train_data_path = os.path.join(ORIGINAL_DATA_FOLDER, 'train.tsv')\n", "test_data_path = os.path.join(ORIGINAL_DATA_FOLDER, 'test.tsv')\n", "sub_data_path = os.path.join(ORIGINAL_DATA_FOLDER, 'sampleSubmission.csv')\n", "\n", "train_df = pd.read_csv(train_data_path, sep=\"\\t\")\n", "test_df = pd.read_csv(test_data_path, sep=\"\\t\")\n", "sub_df = pd.read_csv(sub_data_path, sep=\",\")"]}, {"cell_type": "markdown", "metadata": {"_uuid": "ee07dfaceeb2d800b4c95430a5f44d7386fed119"}, "source": ["# EDA"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"_uuid": "abc33cf6801467c6c8ccd5266961d5e74a70b030"}, "outputs": [], "source": ["import seaborn as sns\n", "from sklearn.feature_extraction import text as sktext"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"_uuid": "33485dab7ac4678cc77fed13b2c8e500d341f72f"}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"_uuid": "c2e0e484aacbb21ebb2807c79beca5aa054c3830"}, "outputs": [], "source": ["test_df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "641a74568482c8ad42d1ac1c8982a44b84641166"}, "outputs": [], "source": ["sub_df.head()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "c4d3c60c638b8ed36a90102e2f5d0fcb034b9ac4"}, "source": ["## Find Overlapped Phrases Between Train and Test Data"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"_uuid": "0a31536ca50b348303c4980a7535fdea69716d6e"}, "outputs": [], "source": ["overlapped = pd.merge(train_df[[\"Phrase\", \"Sentiment\"]], test_df, on=\"Phrase\", how=\"inner\")\n", "overlap_boolean_mask_test = test_df['Phrase'].isin(overlapped['Phrase'])"]}, {"cell_type": "markdown", "metadata": {"_uuid": "2de53b6baefcd985866f4e3789cb923e7c8d57c8"}, "source": ["## Histogram of phrase length"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "25a101f200f79abef0c91b2fdce721a22ad66b1d"}, "outputs": [], "source": ["print(\"training data phrase length distribution\")\n", "sns.distplot(train_df['Phrase'].map(lambda ele: len(ele)), kde_kws={\"label\": \"train\"})\n", "\n", "print(\"testing data phrase length distribution\")\n", "sns.distplot(test_df[~overlap_boolean_mask_test]['Phrase'].map(lambda ele: len(ele)), kde_kws={\"label\": \"test\"})"]}, {"cell_type": "markdown", "metadata": {"_uuid": "22c203439a2310d54f0283dc4e117307a1afa82d"}, "source": ["## Explore Sentence Id"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"_uuid": "c957e257b2865c258a6d9ce23b9ed15c316b90b8"}, "outputs": [], "source": ["print(\"training and testing data sentences hist:\")\n", "sns.distplot(train_df['SentenceId'], kde_kws={\"label\": \"train\"})\n", "sns.distplot(test_df['SentenceId'], kde_kws={\"label\": \"test\"})"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"_uuid": "6ae6308dd0bb586f7cc6e75619e228f7984116ab"}, "outputs": [], "source": ["print(\"The number of overlapped SentenceId between training and testing data:\")\n", "train_overlapped_sentence_id_df = train_df[train_df['SentenceId'].isin(test_df['SentenceId'])]\n", "print(train_overlapped_sentence_id_df.shape[0])\n", "\n", "del train_overlapped_sentence_id_df\n", "gc.collect()"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"_kg_hide-output": true, "_uuid": "030ab4a34391188a30160731259e21d4611762a2"}, "outputs": [], "source": ["pd.options.display.max_colwidth = 250\n", "print(\"Example of sentence and phrases: \")\n", "\n", "sample_sentence_id = train_df.sample(1)['SentenceId'].values[0]\n", "sample_sentence_group_df = train_df[train_df['SentenceId'] == sample_sentence_id]\n", "sample_sentence_group_df"]}, {"cell_type": "markdown", "metadata": {"_uuid": "6ebe14dacb40043c8d25657d7f64376f5e2fe26b"}, "source": ["## Explore Phrase Text"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c238331d1b5017f585082416782f099064d3f1b9"}, "outputs": [], "source": ["import nltk\n", "import gensim\n", "import operator \n", "from keras.preprocessing import text as ktext"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "63cda17126818957a51f0f0e2080014fc1001be0"}, "outputs": [], "source": ["def build_vocab(texts):\n", "    tk = ktext.Tokenizer(lower = True, filters='')\n", "    tk.fit_on_texts(texts)\n", "    return tk.word_counts\n", "\n", "def check_coverage(vocab, embeddings_index):\n", "    known_words = {}\n", "    unknown_words = {}\n", "    for word in vocab.keys():\n", "        if word in embeddings_index:\n", "            known_words[word] = vocab[word]\n", "            continue\n", "        unknown_words[word] = vocab[word]\n", "\n", "    print('Found embeddings for {:.3%} of vocab'.format(len(known_words) / len(vocab)))\n", "    num_known_words = np.sum(np.asarray(list(known_words.values())))\n", "    num_unknown_words = np.sum(np.asarray(list(unknown_words.values())))\n", "    print('Found embeddings for  {:.3%} of all text'.format(float(num_known_words) / (num_known_words + num_unknown_words)))\n", "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n", "\n", "    return unknown_words"]}, {"cell_type": "markdown", "metadata": {"_uuid": "31f8de19d740ae069dd8b7ef50ba058908eb5eb5"}, "source": ["#### Build Vocabulary"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6f752749067c6c356693877e69be822cfa8a5b33"}, "outputs": [], "source": ["texts = list(train_df['Phrase'].values) + list(test_df['Phrase'].values)\n", "vocab = build_vocab(texts)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b3d513b3174d12e90a85bbe10902ae3ca945f261"}, "source": ["#### Load Embedding"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "baac82443ed73deb1cb58dc953187b98cf3076b9"}, "outputs": [], "source": ["def load_embed(file):\n", "    def get_coefs(word,*arr): \n", "        return word, np.asarray(arr[:len(arr)-1], dtype='float32')\n", "    \n", "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>15)\n", "        \n", "    return embeddings_index"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a2a23b09c2d335df392c94308b2fe52490919015"}, "outputs": [], "source": ["pretrained_w2v_path = os.path.join(DATA_ROOT, \"nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin\")\n", "w2v_google = gensim.models.KeyedVectors.load_word2vec_format(pretrained_w2v_path, binary=True).wv\n", "\n", "pretrained_w2v_path = os.path.join(DATA_ROOT, \"fasttext-crawl-300d-2m/crawl-300d-2M.vec\")\n", "w2v_fasttext = load_embed(pretrained_w2v_path)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "a4eb50a4c137afa85d6f14ab33fca67e048128f7"}, "source": ["#### Check Vocabulary Coverage"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "631006a1d0ae669fbfd1d5a2eb4df0e7cd269b5c"}, "outputs": [], "source": ["print(\"google\")\n", "unknown_vocab = check_coverage(vocab, w2v_google)\n", "print(\"unknown vocabulary:\")\n", "print(unknown_vocab[:50])\n", "\n", "print(\"\\n\")\n", "\n", "print(\"fast text\")\n", "unknown_vocab = check_coverage(vocab, w2v_fasttext)\n", "print(\"unknown vocabulary:\")\n", "print(unknown_vocab[:50])"]}, {"cell_type": "markdown", "metadata": {"_uuid": "86959890d0944cd3c85201f0107881ae82ce2ad6"}, "source": ["1. There are overlapped phrase texts between training and testing data, which should assign training data labels directly instead of getting from prediction.\n", "2. Max text length should be set around 60.\n", "3. There is no overlapped sentence between training and testing data. Within each sentence group, the phraseId order is the pre-order tanversal over the dependency parsing tree of the sentence text. (This might be a very important information as we can utilized the composition as powerful predictive information). \n", "4. Fast Text has higher vocabulary coverage rate. We are able to correct some of oov tokens.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2a37cd70ed44125b3c27e1f0f204c7207e09f175"}, "outputs": [], "source": ["w2v = w2v_fasttext\n", "# del w2v_google, w2v_fasttext, texts, vocab\n", "# gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "09c94783b2b9f99c5d62ea251391642329ec46a6"}, "source": ["# Data Preprocessing"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f15786c0c632835ae7a008114319badd92dce4c8"}, "outputs": [], "source": ["from keras.preprocessing import sequence\n", "import gensim\n", "from sklearn import preprocessing as skp"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b50c845cca35a18a4f2986d03b37eb826c17e109"}, "outputs": [], "source": ["max_len = 50\n", "embed_size = 300\n", "max_features = 30000"]}, {"cell_type": "markdown", "metadata": {"_uuid": "5cd1af62c09ef764aed364830a0d2485ec9bb9af"}, "source": ["## Clean Texts"]}, {"cell_type": "markdown", "metadata": {"_uuid": "a9993bb5735c64ea02463a580ba2b8c720eaa1bf"}, "source": ["### Clean Contractions"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "966cfe2876258a69abf637bb6a96c3d594ccc587"}, "outputs": [], "source": ["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"n't\": \"not\", \"'ve\": \"have\"}"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9d6602592302e1e443bda09a27b1f34126c07ebf"}, "outputs": [], "source": ["def known_contractions(embed):\n", "    known = []\n", "    for contract in contraction_mapping:\n", "        if contract in embed:\n", "            known.append(contract)\n", "    return known"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8e4167a4154d902d1a0d9f0cc9f5e486decf8395"}, "outputs": [], "source": ["known_contract_list = known_contractions(w2v)\n", "print(known_contract_list)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "099a292ee4b2bb5395bd88bf932b8b2ad4ff3a24"}, "outputs": [], "source": ["def clean_contractions(text, mapping):\n", "    specials = [\"\u2019\", \"\u2018\", \"\u00b4\", \"`\"]\n", "    for s in specials:\n", "        text = text.replace(s, \"'\")\n", "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n", "    return text"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "55d7df7c8ce9d61de3c508d9659b5778369fbd9f"}, "outputs": [], "source": ["train_df.loc[:, 'Phrase'] = train_df['Phrase'].map(lambda text: clean_contractions(text, contraction_mapping))\n", "test_df.loc[:, 'Phrase'] = test_df['Phrase'].map(lambda text: clean_contractions(text, contraction_mapping))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7640bddb16132717157fd59155343ed2f9809eb5"}, "outputs": [], "source": ["full_text = list(train_df['Phrase'].values) + list(test_df['Phrase'].values)\n", "vocab = build_vocab(full_text)\n", "check_coverage(vocab, w2v)\n", "print(\"\")"]}, {"cell_type": "markdown", "metadata": {"_uuid": "cb26beaba5b28b122f15e319bec658334856a3c6"}, "source": ["### Clean Special Characters"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9cea2d92050dc84971a21586c8b172796cbdc4e2"}, "outputs": [], "source": ["punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"\u201c\u201d\u2019' + '\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014\u2013&'"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c6e055fafbd9e6296dfac66af814b844941a3ef9"}, "outputs": [], "source": ["punct_mapping = {\"\u2018\": \"'\", \"\u20b9\": \"e\", \"\u00b4\": \"'\", \"\u00b0\": \"\", \"\u20ac\": \"e\", \"\u2122\": \"tm\", \"\u221a\": \" sqrt \", \"\u00d7\": \"x\", \"\u00b2\": \"2\", \"\u2014\": \"-\", \"\u2013\": \"-\", \"\u2019\": \"'\", \"_\": \"-\", \"`\": \"'\", '\u201c': '\"', '\u201d': '\"', '\u201c': '\"', \"\u00a3\": \"e\", '\u221e': 'infinity', '\u03b8': 'theta', '\u00f7': '/', '\u03b1': 'alpha', '\u2022': '.', '\u00e0': 'a', '\u2212': '-', '\u03b2': 'beta', '\u2205': '', '\u00b3': '3', '\u03c0': 'pi', }"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "43915a0a1afe622358d2a189e720e2ba31620357"}, "outputs": [], "source": ["def unknown_punct(embed, punct):\n", "    unknown = ''\n", "    for p in punct:\n", "        if p not in embed:\n", "            unknown += p\n", "            unknown += ' '\n", "    return unknown\n", "\n", "def clean_special_chars(text, punct, mapping):\n", "    for p in mapping:\n", "        text = text.replace(p, mapping[p])\n", "    \n", "    for p in punct:\n", "        text = text.replace(p, f' {p} ')\n", "    \n", "    specials = {'\\u200b': ' ', '\u2026': ' ... ', '\\ufeff': '', '\u0915\u0930\u0928\u093e': '', '\u0939\u0948': ''}  # Other special characters that I have to deal with in last\n", "    for s in specials:\n", "        text = text.replace(s, specials[s])\n", "    \n", "    return text"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c0bb0f76b1b8186548094d7dc6fddc2b52e4feaa"}, "outputs": [], "source": ["print(unknown_punct(w2v, punct))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a0a364a0f3ddeb433ed2630cefb9522c66be2d59"}, "outputs": [], "source": ["train_df.loc[:, 'Phrase'] = train_df['Phrase'].map(lambda text: clean_special_chars(text, punct, punct_mapping))\n", "test_df.loc[:, 'Phrase'] = test_df['Phrase'].map(lambda text: clean_special_chars(text, punct, punct_mapping))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "281a1ea87df13b90cb0e5435c4982b524c5c939d"}, "outputs": [], "source": ["full_text = list(train_df['Phrase'].values) + list(test_df['Phrase'].values)\n", "vocab = build_vocab(full_text)\n", "unknown_vocab = check_coverage(vocab, w2v)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "f7a1a1fb9bce9e51aa4d9df3c70be15e84627da2"}, "source": ["What left are actually names entities"]}, {"cell_type": "markdown", "metadata": {"_uuid": "f1d6dc7fd2cc3c99e7865819ee6a80728cbef563"}, "source": ["### Map The Rest OOV Tokens to \"[ name ]\""]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "42212f7fadb89fedc561e8c19b7a5e8bf820fad5"}, "outputs": [], "source": ["def map_unknown_token(text, dst_token, unknown_vocab_set):\n", "#     token_list = []\n", "#     for t in text.split(\" \"):\n", "#         if t in unknown_vocab_set:\n", "#             token_list.append(dst_token)\n", "#         else:\n", "#             token_list.append(t)\n", "    \n", "#     return \" \".join(token_list)\n", "    return' '.join([dst_token if t.lower() in unknown_vocab_set else t for t in text.split(\" \")])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9f1493d9ec62c60202552259541d0cd1a221e222"}, "outputs": [], "source": ["unknown_vocab_set = set(list(map(\n", "    lambda unknown_vocab_tuple: unknown_vocab_tuple[0],\n", "    unknown_vocab\n", ")))\n", "train_df.loc[:, 'Phrase'] = train_df['Phrase'].map(lambda ele: map_unknown_token(ele, \"[ name ]\", unknown_vocab_set))\n", "test_df.loc[:, 'Phrase'] = test_df['Phrase'].map(lambda ele: map_unknown_token(ele, \"[ name ]\", unknown_vocab_set))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8d5d8fd18f1bbb7c2f88a39684170ecb65533a99"}, "outputs": [], "source": ["full_text = list(train_df['Phrase'].values) + list(test_df['Phrase'].values)\n", "vocab = build_vocab(full_text)\n", "unknown_vocab = check_coverage(vocab, w2v)\n", "print(unknown_vocab)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "506b2f699332c271c1f5250286b038a3f01fb9c9"}, "source": ["## Reconstruct the Parsing Trees"]}, {"cell_type": "code", "execution_count": 38, "metadata": {"_uuid": "03a441ee0299bc153f899f2f02b0608531366d7f"}, "outputs": [], "source": ["class TreeNode:\n", "    phrase_id_tree_info = list()\n", "    \n", "    def __init__(self, left=None, right=None, phrase_id=None):\n", "        self.left = left\n", "        self.right = right\n", "        self.phrase_id = phrase_id\n", "        \n", "    @classmethod\n", "    def build_preorder_tree(cls, df):\n", "        phrase_ids = df['PhraseId'].values.tolist()\n", "        phrases = df['Phrase'].values.tolist()\n", "        \n", "        return TreeNode.__build_preorder_tree(phrases, phrase_ids, 0, len(phrases)-1)\n", "        \n", "    @classmethod\n", "    def __build_preorder_tree(cls, phrases, phrase_ids, lo, hi):\n", "        if lo > hi:\n", "            return None\n", "        root = TreeNode(phrase_id=phrase_ids[lo])\n", "        if lo == hi:\n", "            return root\n", "        \n", "        left_lo = lo + 1\n", "        \n", "        right_lo = lo + 2\n", "        while(right_lo < len(phrases) and phrases[right_lo].lower() in phrases[left_lo].lower()):\n", "            right_lo += 1\n", "        \n", "        root.left = TreeNode.__build_preorder_tree(phrases, phrase_ids, left_lo, right_lo - 1)\n", "        root.right = TreeNode.__build_preorder_tree(phrases, phrase_ids, right_lo, len(phrases)-1)\n", "        return root\n", "    \n", "    @classmethod\n", "    def update_preorder(cls, df):\n", "        phrase_ids = df['PhraseId'].values.tolist()\n", "        phrases = df['Phrase'].values.tolist()\n", "        \n", "        if 'Sentiment' in df.columns.values.tolist():\n", "            sentiments = df['Sentiment'].values.tolist()\n", "        else:\n", "            sentiments = None\n", "        \n", "        TreeNode.__update_preorder(phrases, phrase_ids, sentiments, 0, len(phrases)-1)\n", "        \n", "    @classmethod\n", "    def __update_preorder(cls, phrases, phrase_ids, sentiments, lo, hi):\n", "        if lo > hi:\n", "            return None, None, 2\n", "        if lo == hi:\n", "            TreeNode.phrase_id_tree_info.append([phrase_ids[lo], None, None, 2, 2])\n", "            return phrase_ids[lo], phrases[lo], 2 if sentiments is None else sentiments[lo]\n", "        \n", "        left_lo = lo + 1\n", "        \n", "        right_lo = lo + 2\n", "        while(right_lo < len(phrases) and phrases[right_lo].lower() in phrases[left_lo].lower()):\n", "            right_lo += 1\n", "        \n", "        left_phrase_id, left_phrase, left_sentiment = TreeNode.__update_preorder(phrases, phrase_ids, sentiments, left_lo, right_lo - 1)\n", "        right_phrase_id, right_phrase, right_sentiment = TreeNode.__update_preorder(phrases, phrase_ids, sentiments, right_lo, len(phrases)-1)\n", "        TreeNode.phrase_id_tree_info.append([phrase_ids[lo], left_phrase, right_phrase, left_sentiment, right_sentiment])\n", "        return phrase_ids[lo], phrases[lo], 2 if sentiments is None else sentiments[lo]\n", "        "]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a73b6544720a253fa7ee41e28a20073ce5d67e76"}, "outputs": [], "source": ["def build_sent_id_tree_map(raw_df):\n", "    for sent_id in raw_df['SentenceId'].unique():\n", "        df = raw_df[raw_df['SentenceId'] == sent_id][['PhraseId', 'Phrase']]\n", "        TreeNode.update_preorder(df)\n", "\n", "TreeNode.phrase_id_tree_info = list()\n", "build_sent_id_tree_map(train_df)\n", "build_sent_id_tree_map(test_df)"]}, {"cell_type": "code", "execution_count": 36, "metadata": {"_uuid": "f8b98a4edcd982edd6883d1614aeec9ff49482ed"}, "outputs": [], "source": ["tree_df = pd.DataFrame(np.asarray(TreeNode.phrase_id_tree_info), columns=['PhraseId', 'LeftPhrase', 'RightPhrase'])\n", "train_df = train_df.join(tree_df.set_index('PhraseId'), on='PhraseId')\n", "test_df = test_df.join(tree_df.set_index('PhraseId'), on='PhraseId')"]}, {"cell_type": "code", "execution_count": 37, "metadata": {"_uuid": "eb9a1f2780820db1e21b60077d19b73bc9b3c24d"}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "69e929bce14433c86cda53d35abc91a3b3fd4e72"}, "source": ["### Tokenize Text"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f05a0bcf40751a8e33814fd3314b7f7e1d5149e5"}, "outputs": [], "source": ["full_text = list(train_df['Phrase'].values) + list(test_df[~overlap_boolean_mask_test]['Phrase'].values)\n", "\n", "tk = ktext.Tokenizer(lower = True, filters='')\n", "tk.fit_on_texts(full_text)\n", "train_tokenized = tk.texts_to_sequences(train_df['Phrase'])\n", "test_tokenized = tk.texts_to_sequences(test_df[~overlap_boolean_mask_test]['Phrase'])\n", "\n", "X_train = sequence.pad_sequences(train_tokenized, maxlen = max_len)\n", "X_test = sequence.pad_sequences(test_tokenized, maxlen = max_len)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "d42d7f7ad3c09838e1648beb5743dbf4e313a543"}, "source": ["### Build embedding matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3467eb40c92d5490a26629f6ab6c7505b8439979"}, "outputs": [], "source": ["word_index = tk.word_index\n", "nb_words = min(max_features, len(word_index))\n", "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n", "for word, i in word_index.items():\n", "    if i >= max_features: continue\n", "    embedding_vector = None\n", "    if word in w2v:\n", "        embedding_vector = w2v[word]\n", "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n", "        \n", "del w2v\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "26e06e8aeabd698b0fe2fb208f2c4ec2855babcd"}, "source": ["### Encode labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "57a0df2d2e98b1b1a8edc5ef87dd26f4f1f5d63c"}, "outputs": [], "source": ["y_train = train_df['Sentiment']\n", "\n", "led = skp.LabelEncoder()\n", "led.fit(y_train.values)\n", "\n", "y_train = led.transform(y_train.values)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "4675184968f46ed87fbd703696978dc3535ce89e"}, "source": ["# Define Keras Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "391b187f5f79d60fc329dd8a805708ac71937b5b"}, "outputs": [], "source": ["import tensorflow as tf\n", "\n", "from keras import callbacks as kc\n", "from keras import optimizers as ko\n", "from keras import initializers, regularizers, constraints\n", "from keras.engine import Layer\n", "import keras.backend as K"]}, {"cell_type": "markdown", "metadata": {"_uuid": "413a0fcd52787baf4cb702cc1074b8086675b1ba"}, "source": ["## Define Attention Layer"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e59457ba4f41bd4082188ccacff7f1cf8601545c"}, "outputs": [], "source": ["def _dot_product(x, kernel):\n", "    \"\"\"\n", "    Wrapper for dot product operation, in order to be compatible with both\n", "    Theano and Tensorflow\n", "    Args:\n", "        x (): input\n", "        kernel (): weights\n", "    Returns:\n", "    \"\"\"\n", "    if K.backend() == 'tensorflow':\n", "        # todo: check that this is correct\n", "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n", "    else:\n", "        return K.dot(x, kernel)\n", "    \n", "    \n", "class AttentionWeight(Layer):\n", "    \"\"\"\n", "        This code is a modified version of cbaziotis implementation:  GithubGist cbaziotis/AttentionWithContext.py\n", "        Attention operation, with a context/query vector, for temporal data.\n", "        Supports Masking.\n", "        Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n", "        \"Hierarchical Attention Networks for Document Classification\"\n", "        by using a context vector to assist the attention\n", "        # Input shape\n", "            3D tensor with shape: `(samples, steps, features)`.\n", "        # Output shape\n", "            2D tensor with shape: `(samples, steps)`.\n", "        :param kwargs:\n", "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n", "        The dimensions are inferred based on the output shape of the RNN.\n", "        Example:\n", "            model.add(LSTM(64, return_sequences=True))\n", "            model.add(AttentionWeight())\n", "        \"\"\"\n", "\n", "    def __init__(self,\n", "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n", "                 W_constraint=None, u_constraint=None, b_constraint=None,\n", "                 bias=True, **kwargs):\n", "\n", "        self.supports_masking = True\n", "        self.init = initializers.get('glorot_uniform')\n", "\n", "        self.W_regularizer = regularizers.get(W_regularizer)\n", "        self.u_regularizer = regularizers.get(u_regularizer)\n", "        self.b_regularizer = regularizers.get(b_regularizer)\n", "\n", "        self.W_constraint = constraints.get(W_constraint)\n", "        self.u_constraint = constraints.get(u_constraint)\n", "        self.b_constraint = constraints.get(b_constraint)\n", "\n", "        self.bias = bias\n", "        super(AttentionWeight, self).__init__(**kwargs)\n", "\n", "    def build(self, input_shape):\n", "        assert len(input_shape) == 3\n", "\n", "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n", "                                 initializer=self.init,\n", "                                 name='{}_W'.format(self.name),\n", "                                 regularizer=self.W_regularizer,\n", "                                 constraint=self.W_constraint)\n", "        if self.bias:\n", "            self.b = self.add_weight((input_shape[-1],),\n", "                                     initializer='zero',\n", "                                     name='{}_b'.format(self.name),\n", "                                     regularizer=self.b_regularizer,\n", "                                     constraint=self.b_constraint)\n", "\n", "        self.u = self.add_weight((input_shape[-1],),\n", "                                 initializer=self.init,\n", "                                 name='{}_u'.format(self.name),\n", "                                 regularizer=self.u_regularizer,\n", "                                 constraint=self.u_constraint)\n", "\n", "        super(AttentionWeight, self).build(input_shape)\n", "\n", "    def compute_mask(self, input, input_mask=None):\n", "        # do not pass the mask to the next layers\n", "        return None\n", "\n", "    def call(self, x, mask=None):\n", "        uit = _dot_product(x, self.W)\n", "\n", "        if self.bias:\n", "            uit += self.b\n", "\n", "        uit = K.tanh(uit)\n", "        ait = _dot_product(uit, self.u)\n", "\n", "        a = K.exp(ait)\n", "\n", "        # apply mask after the exp. will be re-normalized next\n", "        if mask is not None:\n", "            # Cast the mask to floatX to avoid float64 upcasting in theano\n", "            a *= K.cast(mask, K.floatx())\n", "\n", "        # in some cases especially in the early stages of training the sum may be almost zero\n", "        # and this results in NaN's. A workaround is to add a very small positive number \u03b5 to the sum.\n", "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n", "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n", "\n", "        return a\n", "\n", "    def compute_output_shape(self, input_shape):\n", "        return input_shape[0], input_shape[1]\n", "\n", "    def get_config(self):\n", "        config = {\n", "            'W_regularizer': regularizers.serialize(self.W_regularizer),\n", "            'u_regularizer': regularizers.serialize(self.u_regularizer),\n", "            'b_regularizer': regularizers.serialize(self.b_regularizer),\n", "            'W_constraint': constraints.serialize(self.W_constraint),\n", "            'u_constraint': constraints.serialize(self.u_constraint),\n", "            'b_constraint': constraints.serialize(self.b_constraint),\n", "            'bias': self.bias\n", "        }\n", "        base_config = super(AttentionWeight, self).get_config()\n", "        return dict(list(base_config.items()) + list(config.items()))"]}, {"cell_type": "markdown", "metadata": {"_uuid": "c3e4ae86f2e94275e3bc3de33a5eb9b1f8327caa"}, "source": ["## Define Models"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ab6fd1ea52e5cdeb110d5ef79e0cde12b195c586"}, "outputs": [], "source": ["def is_integer(val):\n", "    return isinstance(val, (int, np.int_))\n", "\n", "def predict(keras_model, x, learning_phase=0):\n", "\n", "    if isinstance(keras_model.input, list):\n", "        f = backend.function(\n", "            keras_model.input + [backend.learning_phase()],\n", "            [keras_model.output, ]\n", "        )\n", "        y = f(tuple(x) + (learning_phase,))[0]\n", "    else:\n", "        f = backend.function(\n", "            [keras_model.input, backend.learning_phase()],\n", "            [keras_model.output, ]\n", "        )\n", "        y = f((x, learning_phase))[0]\n", "    return y\n", "    \n", "\n", "def build_birnn_attention_model(\n", "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, \n", "        item_embedding=None, rnn_depth=1, mlp_depth=1, num_att_channel=1,\n", "        drop_out=0.5, rnn_drop_out=0., rnn_state_drop_out=0.,\n", "        trainable_embedding=False, gpu=False, return_customized_layers=False):\n", "    \"\"\"\n", "    Create A Bidirectional Attention Model.\n", "\n", "    :param voca_dim: vocabulary dimension size.\n", "    :param time_steps: the length of input\n", "    :param output_dim: the output dimension size\n", "    :param rnn_dim: rrn dimension size\n", "    :param mlp_dim: the dimension size of fully connected layer\n", "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n", "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n", "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n", "        If item_embedding is None, then connect input tensor to RNN layer directly.\n", "    :param rnn_depth: rnn depth\n", "    :param mlp_depth: the depth of fully connected layers\n", "    :param num_att_channel: the number of attention channels, this can be used to mimic multi-head attention mechanism\n", "    :param drop_out: dropout rate of fully connected layers\n", "    :param rnn_drop_out: dropout rate of rnn layers\n", "    :param rnn_state_drop_out: dropout rate of rnn state tensor\n", "    :param trainable_embedding: boolean\n", "    :param gpu: boolean, default=False\n", "        If True, CuDNNLSTM is used instead of LSTM for RNN layer.\n", "    :param return_customized_layers: boolean, default=False\n", "        If True, return model and customized object dictionary, otherwise return model only\n", "    :return: keras model\n", "    \"\"\"\n", "    \n", "    if item_embedding is not None:\n", "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n", "        x = inputs\n", "\n", "        # item embedding\n", "        if isinstance(item_embedding, np.ndarray):\n", "            assert voca_dim == item_embedding.shape[0]\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n", "                weights=[item_embedding, ], trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        elif utils.is_integer(item_embedding):\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding, input_length=time_steps,\n", "                trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        else:\n", "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n", "    else:\n", "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n", "        x = inputs\n", "    \n", "    x = layers.SpatialDropout1D(rnn_drop_out, name='rnn_spatial_droutout_layer')(x)\n", "\n", "    if gpu:\n", "        # rnn encoding\n", "        for i in range(rnn_depth):\n", "            x = layers.Bidirectional(\n", "                layers.CuDNNLSTM(rnn_dim, return_sequences=True),\n", "                name='bi_lstm_layer' + str(i))(x)\n", "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n", "            x = layers.Dropout(rate=rnn_drop_out, name=\"rnn_dropout_layer\" + str(i))(x)\n", "    else:\n", "        # rnn encoding\n", "        for i in range(rnn_depth):\n", "            x = layers.Bidirectional(\n", "                layers.LSTM(rnn_dim, return_sequences=True, dropout=rnn_drop_out, recurrent_dropout=rnn_state_drop_out),\n", "                name='bi_lstm_layer' + str(i))(x)\n", "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n", "\n", "    # attention\n", "    attention_heads = []\n", "    x_per = layers.Permute((2, 1), name='permuted_attention_x')(x)\n", "    for h in range(max(1, num_att_channel)):\n", "        attention = AttentionWeight(name=\"attention_weights_layer\" + str(h))(x)\n", "        xx = layers.Dot([2, 1], name='focus_head' + str(h) + '_layer0')([x_per, attention])\n", "        attention_heads.append(xx)\n", "\n", "    if num_att_channel > 1:\n", "        x = layers.Concatenate(name='focus_layer0')(attention_heads)\n", "    else:\n", "        x = attention_heads[0]\n", "\n", "    x = layers.BatchNormalization(name='focused_batch_norm_layer')(x)\n", "    x = layers.Dropout(rate=rnn_drop_out, name=\"focused_dropout_layer\")(x)\n", "\n", "    # MLP Layers\n", "    for i in range(mlp_depth - 1):\n", "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n", "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n", "\n", "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n", "\n", "    model = models.Model(inputs, outputs)\n", "\n", "    if return_customized_layers:\n", "        return model, {'AttentionWeight': AttentionWeight}\n", "    return model\n", "\n", "\n", "def build_cnn_model(\n", "        voca_dim, time_steps, output_dim, mlp_dim, num_filters, filter_sizes,\n", "        item_embedding=None, mlp_depth=1,\n", "        drop_out=0.5, cnn_drop_out=0.5, pooling='max', padding='valid',\n", "        trainable_embedding=False, return_customized_layers=False):\n", "    \"\"\"\n", "    Create A CNN Model.\n", "\n", "    :param voca_dim: vocabulary dimension size.\n", "    :param time_steps: the length of input\n", "    :param output_dim: the output dimension size\n", "    :param num_filters: list of integers\n", "        The number of filters.\n", "    :param filter_sizes: list of integers\n", "        The kernel size.\n", "    :param mlp_dim: the dimension size of fully connected layer\n", "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n", "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n", "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n", "        If item_embedding is None, then connect input tensor to RNN layer directly.\n", "    :param mlp_depth: the depth of fully connected layers\n", "    :param drop_out: dropout rate of fully connected layers\n", "    :param cnn_drop_out: dropout rate of between cnn layer and fully connected layers\n", "    :param pooling: str, either 'max' or 'average'\n", "        Pooling method.\n", "    :param padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive).\n", "        Padding method.\n", "    :param trainable_embedding: boolean\n", "    :param return_customized_layers: boolean, default=False\n", "        If True, return model and customized object dictionary, otherwise return model only\n", "    :return: keras model\n", "    \"\"\"\n", "\n", "    if item_embedding is not None:\n", "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n", "        x = inputs\n", "\n", "        # item embedding\n", "        if isinstance(item_embedding, np.ndarray):\n", "            assert voca_dim == item_embedding.shape[0]\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n", "                weights=[item_embedding, ], trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        elif utils.is_integer(item_embedding):\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding, input_length=time_steps,\n", "                trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        else:\n", "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n", "    else:\n", "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n", "        x = inputs\n", "    \n", "    x = layers.SpatialDropout1D(cnn_drop_out, name='cnn_spatial_droutout_layer')(x)\n", "\n", "    pooled_outputs = []\n", "    for i in range(len(filter_sizes)):\n", "        conv = layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu')(x)\n", "        if pooling == 'max':\n", "            conv = layers.GlobalMaxPooling1D(name='global_pooling_layer' + str(i))(conv)\n", "        else:\n", "            conv = layers.GlobalAveragePooling1D(name='global_pooling_layer' + str(i))(conv)\n", "        pooled_outputs.append(conv)\n", "\n", "    x = layers.Concatenate(name='concated_layer')(pooled_outputs)\n", "    x = layers.Dropout(cnn_drop_out, name='conv_dropout_layer')(x)\n", "    x = layers.BatchNormalization(name=\"batch_norm_layer\")(x)\n", "\n", "    # MLP Layers\n", "    for i in range(mlp_depth - 1):\n", "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n", "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n", "\n", "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n", "\n", "    model = models.Model(inputs, outputs)\n", "\n", "    if return_customized_layers:\n", "        return model, dict()\n", "\n", "    return model\n", "\n", "\n", "def build_birnn_cnn_model(\n", "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes,\n", "        item_embedding=None, rnn_depth=1, mlp_depth=1,\n", "        drop_out=0.5, rnn_drop_out=0.5, rnn_state_drop_out=0.5, cnn_drop_out=0.5, pooling='max', padding='valid',\n", "        trainable_embedding=False, gpu=False, return_customized_layers=False):\n", "    \"\"\"\n", "    Create A Bidirectional CNN Model.\n", "\n", "    :param voca_dim: vocabulary dimension size.\n", "    :param time_steps: the length of input\n", "    :param output_dim: the output dimension size\n", "    :param rnn_dim: rrn dimension size\n", "    :param num_filters: list of integers\n", "        The number of filters.\n", "    :param filter_sizes: list of integers\n", "        The kernel size.\n", "    :param mlp_dim: the dimension size of fully connected layer\n", "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n", "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n", "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n", "        If item_embedding is None, then connect input tensor to RNN layer directly.\n", "    :param rnn_depth: rnn depth\n", "    :param mlp_depth: the depth of fully connected layers\n", "    :param num_att_channel: the number of attention channels, this can be used to mimic multi-head attention mechanism\n", "    :param drop_out: dropout rate of fully connected layers\n", "    :param rnn_drop_out: dropout rate of rnn layers\n", "    :param rnn_state_drop_out: dropout rate of rnn state tensor\n", "    :param cnn_drop_out: dropout rate of between cnn layer and fully connected layers\n", "    :param pooling: str, either 'max' or 'average'\n", "        Pooling method.\n", "    :param padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive).\n", "        Padding method.\n", "    :param trainable_embedding: boolean\n", "    :param gpu: boolean, default=False\n", "        If True, CuDNNLSTM is used instead of LSTM for RNN layer.\n", "    :param return_customized_layers: boolean, default=False\n", "        If True, return model and customized object dictionary, otherwise return model only\n", "    :return: keras model\n", "    \"\"\"\n", "\n", "    if item_embedding is not None:\n", "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n", "        x = inputs\n", "\n", "        # item embedding\n", "        if isinstance(item_embedding, np.ndarray):\n", "            assert voca_dim == item_embedding.shape[0]\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n", "                weights=[item_embedding, ], trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        elif utils.is_integer(item_embedding):\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding, input_length=time_steps,\n", "                trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        else:\n", "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n", "    else:\n", "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n", "        x = inputs\n", "        \n", "    x = layers.SpatialDropout1D(rnn_drop_out, name='rnn_spatial_droutout_layer')(x)\n", "\n", "    if gpu:\n", "        # rnn encoding\n", "        for i in range(rnn_depth):\n", "            x = layers.Bidirectional(\n", "                layers.CuDNNLSTM(rnn_dim, return_sequences=True),\n", "                name='bi_lstm_layer' + str(i))(x)\n", "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n", "            x = layers.Dropout(rate=rnn_drop_out, name=\"rnn_dropout_layer\" + str(i))(x)\n", "    else:\n", "        # rnn encoding\n", "        for i in range(rnn_depth):\n", "            x = layers.Bidirectional(\n", "                layers.LSTM(rnn_dim, return_sequences=True, dropout=rnn_drop_out, recurrent_dropout=rnn_state_drop_out),\n", "                name='bi_lstm_layer' + str(i))(x)\n", "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n", "\n", "    pooled_outputs = []\n", "    for i in range(len(filter_sizes)):\n", "        conv = layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu')(x)\n", "        if pooling == 'max':\n", "            conv = layers.GlobalMaxPooling1D(name='global_pooling_layer' + str(i))(conv)\n", "        else:\n", "            conv = layers.GlobalAveragePooling1D(name='global_pooling_layer' + str(i))(conv)\n", "        pooled_outputs.append(conv)\n", "\n", "    x = layers.Concatenate(name='concated_layer')(pooled_outputs)\n", "    x = layers.BatchNormalization(name=\"batch_norm_layer\")(x)\n", "    x = layers.Dropout(cnn_drop_out, name='conv_dropout_layer')(x)\n", "\n", "    # MLP Layers\n", "    for i in range(mlp_depth - 1):\n", "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n", "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n", "\n", "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n", "\n", "    model = models.Model(inputs, outputs)\n", "\n", "    if return_customized_layers:\n", "        return model, dict()\n", "\n", "    return model\n", "\n", "def build_birnn_hierarchy_cnn_model(\n", "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes, \n", "        dilation_rates=1, strides=1,\n", "        item_embedding=None, rnn_depth=1, mlp_depth=1,\n", "        drop_out=0.5, rnn_drop_out=0.5, rnn_state_drop_out=0.5, cnn_drop_out=0.5, pooling='max', padding='valid',\n", "        trainable_embedding=False, gpu=False, return_customized_layers=False):\n", "    \"\"\"\n", "    Create A Bidirectional CNN Model.\n", "\n", "    :param voca_dim: vocabulary dimension size.\n", "    :param time_steps: the length of input\n", "    :param output_dim: the output dimension size\n", "    :param rnn_dim: rrn dimension size\n", "    :param num_filters: list of integers\n", "        The number of filters.\n", "    :param filter_sizes: list of integers\n", "        The kernel size.\n", "    :param mlp_dim: the dimension size of fully connected layer\n", "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n", "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n", "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n", "        If item_embedding is None, then connect input tensor to RNN layer directly.\n", "    :param rnn_depth: rnn depth\n", "    :param mlp_depth: the depth of fully connected layers\n", "    :param num_att_channel: the number of attention channels, this can be used to mimic multi-head attention mechanism\n", "    :param drop_out: dropout rate of fully connected layers\n", "    :param rnn_drop_out: dropout rate of rnn layers\n", "    :param rnn_state_drop_out: dropout rate of rnn state tensor\n", "    :param cnn_drop_out: dropout rate of between cnn layer and fully connected layers\n", "    :param pooling: str, either 'max' or 'average'\n", "        Pooling method.\n", "    :param padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive).\n", "        Padding method.\n", "    :param trainable_embedding: boolean\n", "    :param gpu: boolean, default=False\n", "        If True, CuDNNLSTM is used instead of LSTM for RNN layer.\n", "    :param return_customized_layers: boolean, default=False\n", "        If True, return model and customized object dictionary, otherwise return model only\n", "    :return: keras model\n", "    \"\"\"\n", "\n", "    if item_embedding is not None:\n", "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n", "        x = inputs\n", "\n", "        # item embedding\n", "        if isinstance(item_embedding, np.ndarray):\n", "            assert voca_dim == item_embedding.shape[0]\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n", "                weights=[item_embedding, ], trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        elif utils.is_integer(item_embedding):\n", "            x = layers.Embedding(\n", "                voca_dim, item_embedding, input_length=time_steps,\n", "                trainable=trainable_embedding,\n", "                mask_zero=False, name='embedding_layer0'\n", "            )(x)\n", "        else:\n", "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n", "    else:\n", "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n", "        x = inputs\n", "        \n", "    x = layers.SpatialDropout1D(rnn_drop_out, name='rnn_spatial_droutout_layer')(x)\n", "\n", "    if gpu:\n", "        # rnn encoding\n", "        for i in range(rnn_depth):\n", "            x = layers.Bidirectional(\n", "                layers.CuDNNLSTM(rnn_dim, return_sequences=True),\n", "                name='bi_lstm_layer' + str(i))(x)\n", "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n", "            x = layers.Dropout(rate=rnn_drop_out, name=\"rnn_dropout_layer\" + str(i))(x)\n", "    else:\n", "        # rnn encoding\n", "        for i in range(rnn_depth):\n", "            x = layers.Bidirectional(\n", "                layers.LSTM(rnn_dim, return_sequences=True, dropout=rnn_drop_out, recurrent_dropout=rnn_state_drop_out),\n", "                name='bi_lstm_layer' + str(i))(x)\n", "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n", "\n", "    for i in range(len(filter_sizes)):\n", "        if is_integer(dilation_rates):\n", "            di_rate = dilation_rates\n", "        else:\n", "            di_rate = dilation_rates[i]\n", "        \n", "        if is_integer(strides):\n", "            std = strides\n", "        else:\n", "            std = strides[i]\n", "            \n", "        x = layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu', dilation_rate=di_rate, strides=std)(x)\n", "        \n", "    if pooling == 'max':\n", "        x = layers.GlobalMaxPooling1D(name='global_pooling_layer')(x)\n", "    else:\n", "        x = layers.GlobalAveragePooling1D(name='global_pooling_layer')(x)\n", "\n", "    x = layers.BatchNormalization(name=\"batch_norm_layer\")(x)\n", "    x = layers.Dropout(cnn_drop_out, name='conv_dropout_layer')(x)\n", "\n", "    # MLP Layers\n", "    for i in range(mlp_depth - 1):\n", "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n", "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n", "\n", "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n", "\n", "    model = models.Model(inputs, outputs)\n", "\n", "    if return_customized_layers:\n", "        return model, dict()\n", "\n", "    return model"]}, {"cell_type": "markdown", "metadata": {"_uuid": "0f8a54b45eb4838d7459e6db57e9f0a95bfe7e60"}, "source": ["# Build and Train Models"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9dd9a276408dd3543d44e4e82cd8086024f56b3f"}, "outputs": [], "source": ["from keras.utils import model_to_dot\n", "from keras import models\n", "from keras import layers\n", "\n", "import matplotlib.pyplot as plt\n", "from IPython.display import SVG"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "83515918a1861d9aa3ef7751aaf05ca1635d9620"}, "outputs": [], "source": ["histories = list()\n", "iterations = list()\n", "model_builders = list()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "d514af1525ce6dd02614bfdc4c1c707617eceade"}, "source": ["## CNN Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9fcdab9f1bfb6d88b2e3d110dea35f87c71dbf51"}, "outputs": [], "source": ["def build_model1():\n", "    voca_dim = embedding_matrix.shape[0]\n", "    time_steps = max_len\n", "    output_dim = led.classes_.shape[0]\n", "    mlp_dim = 50\n", "    num_filters = [128, 128, 128]\n", "    filter_sizes = [1, 3, 5]\n", "    item_embedding = embedding_matrix\n", "    mlp_depth = 2\n", "    cnn_drop_out = 0.2\n", "    mlp_drop_out = 0.2\n", "    padding = 'causal'\n", "\n", "    return build_cnn_model(\n", "        voca_dim, time_steps, output_dim, mlp_dim, num_filters, filter_sizes, \n", "        item_embedding=item_embedding, mlp_depth=2, cnn_drop_out=cnn_drop_out,\n", "        padding=padding,\n", "        return_customized_layers=True\n", "    )\n", "\n", "model_builders.append(build_model1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f5e58b1f129140130e4559b1610c307d50f15f8d"}, "outputs": [], "source": ["model, cnn_cl = build_model1()\n", "print(model.summary())"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "82b16272ecfe86ee0dc3e5731d4e33aa016842c3"}, "outputs": [], "source": ["adam = ko.Nadam()\n", "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n", "\n", "file_path = \"best_cnn_model.hdf5\"\n", "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n", "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n", "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n", "\n", "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "del model, history\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "db9ac105bd787c06a1371eaf61936b1159c1645c"}, "source": ["## Attention RNN Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "46d854b13ad591f5d349af3007a0b17559f72535"}, "outputs": [], "source": ["def build_model2():\n", "    voca_dim = embedding_matrix.shape[0]\n", "    time_steps = max_len\n", "    output_dim = led.classes_.shape[0]\n", "    rnn_dim = 100\n", "    mlp_dim = 50\n", "    item_embedding = embedding_matrix\n", "    rnn_depth=1\n", "    mlp_depth = 2\n", "    rnn_drop_out = 0.3\n", "    rnn_state_drop_out = 0.3\n", "    mlp_drop_out = 0.2\n", "    num_att_channel = 1\n", "    gpu=True\n", "    \n", "    return build_birnn_attention_model(\n", "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, \n", "        item_embedding=item_embedding, rnn_depth=rnn_depth, mlp_depth=mlp_depth, num_att_channel=num_att_channel,\n", "        rnn_drop_out=rnn_drop_out, rnn_state_drop_out=rnn_state_drop_out,\n", "        gpu=gpu, return_customized_layers=True\n", "    )\n", "\n", "model_builders.append(build_model2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2a264d510a763478c67b572c14366ae2144ce3f8"}, "outputs": [], "source": ["model, rnn_cl = build_model2()\n", "print(model.summary())"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d40857a43116f8587f28ba89baef17b519c58d45"}, "outputs": [], "source": ["adam = ko.Nadam(clipnorm=2.0)\n", "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n", "\n", "file_path = \"best_birnn_attention_model.hdf5\"\n", "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n", "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n", "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n", "\n", "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "del model, history\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "e53b77f6a8507bc64a2de060a1718366ee24200f"}, "source": ["## RNN-CNN Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1a3294e306d5ac35c0bf0fa039fc17099a83f367"}, "outputs": [], "source": ["def build_model3():\n", "    voca_dim = embedding_matrix.shape[0]\n", "    time_steps = max_len\n", "    output_dim = led.classes_.shape[0]\n", "    rnn_dim = 100\n", "    mlp_dim = 50\n", "    item_embedding = embedding_matrix\n", "    rnn_depth=1\n", "    mlp_depth = 2\n", "    num_filters = [128, 128, 128]\n", "    filter_sizes = [1, 3, 5]\n", "    cnn_drop_out = 0.2\n", "    rnn_drop_out = 0.3\n", "    rnn_state_drop_out = 0.3\n", "    mlp_drop_out = 0.2\n", "    padding = 'causal'\n", "    gpu=True\n", "    \n", "    return build_birnn_cnn_model(\n", "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes, \n", "        item_embedding=item_embedding, rnn_depth=rnn_depth, mlp_depth=mlp_depth,\n", "        rnn_drop_out=rnn_drop_out, rnn_state_drop_out=rnn_state_drop_out, cnn_drop_out=cnn_drop_out,\n", "        padding=padding,\n", "        gpu=gpu, return_customized_layers=True\n", "    )\n", "\n", "model_builders.append(build_model3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c9e49dcf31d32f1b4717a3ccf665aacad1a1e165"}, "outputs": [], "source": ["model, rc_cl = build_model3()\n", "print(model.summary())"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "39f08fded4a3019dfd07504da932064425f8a16b"}, "outputs": [], "source": ["adam = ko.Nadam(clipnorm=2.0)\n", "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n", "\n", "file_path = \"best_birnn_cnn_model.hdf5\"\n", "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n", "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n", "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n", "\n", "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "del model, history\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b4165b5741a971bb4a651a9d513ee2e1d3c19aa5"}, "source": ["## RNN-HierarchyCNN"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0ee00f133652fa813b55f4f223b87beddb588bcf"}, "outputs": [], "source": ["def build_model4():\n", "    voca_dim = embedding_matrix.shape[0]\n", "    time_steps = max_len\n", "    output_dim = led.classes_.shape[0]\n", "    rnn_dim = 100\n", "    mlp_dim = 50\n", "    item_embedding = embedding_matrix\n", "    rnn_depth=1\n", "    mlp_depth = 2\n", "    num_filters = [128, 256, 512]\n", "    filter_sizes = [1, 3, 5]\n", "    dilation_rates = [1, 2, 4]\n", "    strides=1\n", "    cnn_drop_out = 0.2\n", "    rnn_drop_out = 0.3\n", "    rnn_state_drop_out = 0.3\n", "    mlp_drop_out = 0.2\n", "    padding = 'causal'\n", "    gpu=True\n", "    \n", "    return build_birnn_hierarchy_cnn_model(\n", "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes, \n", "        dilation_rates=dilation_rates, strides=strides,\n", "        item_embedding=item_embedding, rnn_depth=rnn_depth, mlp_depth=mlp_depth,\n", "        rnn_drop_out=rnn_drop_out, rnn_state_drop_out=rnn_state_drop_out, cnn_drop_out=cnn_drop_out,\n", "        padding=padding,\n", "        gpu=gpu, return_customized_layers=True\n", "    )\n", "\n", "model_builders.append(build_model4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d85a1e00009b635853e8928c83b3733a32f37d48"}, "outputs": [], "source": ["model, rhc_cl = build_model4()\n", "print(model.summary())"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "276d7133a37091457cdead0efb311ce01e20f689"}, "outputs": [], "source": ["adam = ko.Nadam(clipnorm=2.0)\n", "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n", "\n", "file_path = \"best_birnn_hierarchy_cnn_model.hdf5\"\n", "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n", "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n", "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n", "\n", "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n", "del model, history\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "db9a896a94311439b6eda66aa247e828fb57eca2"}, "source": ["# Make Prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "428880b633b909db6d5056d4751ce3dabc9fd1a5"}, "outputs": [], "source": ["histories = np.asarray(histories)\n", "\n", "model_paths = [\n", "    \"best_cnn_model.hdf5\",\n", "    \"best_birnn_attention_model.hdf5\",\n", "    \"best_birnn_cnn_model.hdf5\",\n", "    \"best_birnn_hierarchy_cnn_model.hdf5\"\n", "]\n", "\n", "cls =[\n", "    cnn_cl, rnn_cl, rc_cl, rhc_cl\n", "]\n", "\n", "pred = list()\n", "for idx in range(len(model_paths)):\n", "    model = models.load_model(model_paths[idx], cls[idx])\n", "    pred_tmp = model.predict(X_test, batch_size = 1024, verbose = 1)\n", "    pred.append(np.round(np.argmax(pred_tmp, axis=1)).astype(int))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3ef083a0a29b808560344a0d52d1fb5a77a3a2da"}, "outputs": [], "source": ["def majority_vote(preds_data_point):\n", "    unique, counts = np.unique(preds_data_point, return_counts=True)\n", "    idx = np.argmax(counts)\n", "    return unique[idx]\n", "\n", "pred = np.asarray(pred)\n", "predictions = list()\n", "for i in range(pred.shape[1]):\n", "    predictions.append(majority_vote(pred[:, i]))\n", "predictions = np.asarray(predictions)\n", "\n", "test_not_overlap_df = test_df[~overlap_boolean_mask_test]\n", "test_not_overlap_df['Sentiment'] = predictions\n", "\n", "res_df = pd.concat([overlapped, test_not_overlap_df], sort=True)[sub_df.columns.values.tolist()]\n", "\n", "assert sub_df.shape[0] == res_df.shape[0]\n", "assert sub_df.shape[1] == res_df.shape[1]\n", "\n", "res_df.to_csv(\"submission.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 1}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dlmslib.torch_models import trees, nlp_models\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../input/'\n",
    "ORIGINAL_DATA_FOLDER = os.path.join(DATA_ROOT, 'movie-review-sentiment-analysis-kernels-only')\n",
    "TREEBANK_DATA_FOLDER = os.path.join(DATA_ROOT, 'stanford-sentiment-treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree_bank_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as fid:\n",
    "        tree_list = [trees.LabeledTextBinaryTreeNode.parse_ptb_string(l) for l in fid.readlines()]\n",
    "    return tree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(TREEBANK_DATA_FOLDER, 'train.txt')\n",
    "test_data_path = os.path.join(TREEBANK_DATA_FOLDER, 'test.txt')\n",
    "dev_data_path = os.path.join(TREEBANK_DATA_FOLDER, 'dev.txt')\n",
    "\n",
    "train_trees = read_tree_bank_file(train_data_path)\n",
    "test_trees = read_tree_bank_file(test_data_path)\n",
    "dev_trees = read_tree_bank_file(dev_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr[:len(arr)-1], dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>15)\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_w2v_path = os.path.join(DATA_ROOT, \"fasttext-crawl-300d-2m/crawl-300d-2M.vec\")\n",
    "w2v_fasttext = load_embed(pretrained_w2v_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_TOKEN = '<UNK>'\n",
    "EMB_DIM = 300\n",
    "\n",
    "def map_unknown_token(tree, embeddings_index):\n",
    "    if tree is None:\n",
    "        return\n",
    "    \n",
    "    word = tree.text\n",
    "    if word not in embeddings_index:\n",
    "            tree.text = UNKNOWN_TOKEN\n",
    "    \n",
    "    map_unknown_token(tree.left, embeddings_index)\n",
    "    map_unknown_token(tree.right, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in train_trees:\n",
    "    map_unknown_token(tree, w2v_fasttext)\n",
    "for tree in test_trees:\n",
    "    map_unknown_token(tree, w2v_fasttext)\n",
    "for tree in dev_trees:\n",
    "    map_unknown_token(tree, w2v_fasttext)\n",
    "\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocab = list(set(flatten([t.get_leaf_texts() for t in (train_trees + test_trees + dev_trees)])))\n",
    "\n",
    "word2index = {'<UNK>': 0}\n",
    "wv = np.zeros(shape= (len(vocab), EMB_DIM))\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "        wv[word2index[vo]] = w2v_fasttext[vo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 0\n",
    "for tree in (train_trees + test_trees + dev_trees):\n",
    "    MAX_LEN = max(len(tree.get_leaf_texts()), MAX_LEN)\n",
    "\n",
    "hidden_size = 100\n",
    "tracker_size = 100\n",
    "output_size = 5\n",
    "pad_token_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp_models.ThinStackHybridLSTM(wv, hidden_size, tracker_size, output_size, pad_token_index, trainable_embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = nlp_models.ThinStackHybridLSTM.prepare_data(train_trees, word2index, max_len=MAX_LEN, pre_pad_index=pad_token_index, post_pad_index=pad_token_index)\n",
    "test_data = nlp_models.ThinStackHybridLSTM.prepare_data(test_trees, word2index, max_len=MAX_LEN, pre_pad_index=pad_token_index, post_pad_index=pad_token_index)\n",
    "dev_data = nlp_models.ThinStackHybridLSTM.prepare_data(dev_trees, word2index, max_len=MAX_LEN, pre_pad_index=pad_token_index, post_pad_index=pad_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 1.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.03      0.06      0.04        50\n",
      "          1       0.10      0.07      0.08       256\n",
      "          2       0.74      0.38      0.50      1366\n",
      "          3       0.16      0.57      0.25       249\n",
      "          4       0.01      0.02      0.01        61\n",
      "\n",
      "avg / total       0.55      0.34      0.39      1982\n",
      "\n",
      "[0/30] mean_loss : 1.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        46\n",
      "          1       0.07      0.02      0.04       167\n",
      "          2       0.67      0.89      0.77      1308\n",
      "          3       0.10      0.01      0.02       300\n",
      "          4       0.07      0.04      0.05        81\n",
      "\n",
      "avg / total       0.49      0.62      0.54      1902\n",
      "\n",
      "[0/30] mean_loss : 3.70\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.04      0.35      0.07        51\n",
      "          1       0.05      0.05      0.05       184\n",
      "          2       0.98      0.26      0.41      1329\n",
      "          3       0.18      0.46      0.26       263\n",
      "          4       0.06      0.16      0.09        93\n",
      "\n",
      "avg / total       0.71      0.26      0.33      1920\n",
      "\n",
      "[0/30] mean_loss : 2.07\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.04      0.04      0.04        53\n",
      "          1       0.06      0.02      0.02       195\n",
      "          2       0.73      0.86      0.79      1285\n",
      "          3       0.20      0.09      0.12       218\n",
      "          4       0.09      0.15      0.11        47\n",
      "\n",
      "avg / total       0.56      0.64      0.59      1798\n",
      "\n",
      "[0/30] mean_loss : 1.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.02      0.04      0.03        26\n",
      "          1       0.14      0.04      0.07       158\n",
      "          2       0.94      0.70      0.80      1257\n",
      "          3       0.29      0.72      0.42       289\n",
      "          4       0.32      0.27      0.29        82\n",
      "\n",
      "avg / total       0.73      0.62      0.64      1812\n",
      "\n",
      "[0/30] mean_loss : 1.14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.06      0.04      0.05        26\n",
      "          1       0.75      0.07      0.12       178\n",
      "          2       0.74      0.98      0.84      1321\n",
      "          3       0.46      0.08      0.14       272\n",
      "          4       0.20      0.13      0.16        97\n",
      "\n",
      "avg / total       0.66      0.71      0.63      1894\n",
      "\n",
      "[0/30] mean_loss : 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.05      0.08        56\n",
      "          1       0.26      0.09      0.13       199\n",
      "          2       0.77      0.97      0.86      1239\n",
      "          3       0.48      0.11      0.18       210\n",
      "          4       0.14      0.15      0.14        54\n",
      "\n",
      "avg / total       0.64      0.72      0.65      1758\n",
      "\n",
      "[0/30] mean_loss : 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.09      0.13        44\n",
      "          1       0.74      0.14      0.23       226\n",
      "          2       0.77      0.97      0.86      1430\n",
      "          3       0.58      0.21      0.31       285\n",
      "          4       0.18      0.17      0.18        75\n",
      "\n",
      "avg / total       0.70      0.73      0.67      2060\n",
      "\n",
      "[0/30] mean_loss : 0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        45\n",
      "          1       0.62      0.23      0.33       220\n",
      "          2       0.78      0.99      0.87      1354\n",
      "          3       0.72      0.24      0.36       244\n",
      "          4       0.27      0.16      0.20        45\n",
      "\n",
      "avg / total       0.72      0.76      0.71      1908\n",
      "\n",
      "[0/30] mean_loss : 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.06      0.10       106\n",
      "          1       0.42      0.35      0.38       234\n",
      "          2       0.78      0.97      0.86      1343\n",
      "          3       0.71      0.32      0.44       255\n",
      "          4       0.43      0.17      0.24        54\n",
      "\n",
      "avg / total       0.71      0.74      0.70      1992\n",
      "\n",
      "[0/30] mean_loss : 0.79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.07      0.12        45\n",
      "          1       0.90      0.16      0.28       171\n",
      "          2       0.75      0.99      0.85      1223\n",
      "          3       0.69      0.31      0.42       275\n",
      "          4       0.58      0.15      0.24        74\n",
      "\n",
      "avg / total       0.75      0.75      0.69      1788\n",
      "\n",
      "[0/30] mean_loss : 0.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.02      0.04        47\n",
      "          1       0.58      0.36      0.45       220\n",
      "          2       0.80      0.96      0.87      1316\n",
      "          3       0.64      0.45      0.53       300\n",
      "          4       0.52      0.19      0.28        69\n",
      "\n",
      "avg / total       0.73      0.76      0.73      1952\n",
      "\n",
      "[0/30] mean_loss : 0.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.03      0.06        58\n",
      "          1       0.62      0.21      0.32       202\n",
      "          2       0.76      0.99      0.86      1178\n",
      "          3       0.76      0.30      0.43       238\n",
      "          4       0.54      0.17      0.25        42\n",
      "\n",
      "avg / total       0.72      0.75      0.69      1718\n",
      "\n",
      "[0/30] mean_loss : 0.73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.08      0.15        71\n",
      "          1       0.55      0.35      0.43       198\n",
      "          2       0.80      0.96      0.88      1334\n",
      "          3       0.61      0.39      0.48       252\n",
      "          4       0.44      0.13      0.20        55\n",
      "\n",
      "avg / total       0.74      0.77      0.73      1910\n",
      "\n",
      "[0/30] mean_loss : 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.05      0.09        60\n",
      "          1       0.65      0.23      0.34       184\n",
      "          2       0.78      0.98      0.87      1395\n",
      "          3       0.71      0.37      0.48       260\n",
      "          4       0.81      0.17      0.28        77\n",
      "\n",
      "avg / total       0.76      0.77      0.72      1976\n",
      "\n",
      "[0/30] mean_loss : 0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.12      0.21        41\n",
      "          1       0.63      0.28      0.39       170\n",
      "          2       0.84      0.91      0.87      1169\n",
      "          3       0.47      0.68      0.56       239\n",
      "          4       0.89      0.10      0.19        77\n",
      "\n",
      "avg / total       0.77      0.76      0.73      1696\n",
      "\n",
      "[0/30] mean_loss : 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.02      0.05        41\n",
      "          1       0.74      0.25      0.37       172\n",
      "          2       0.78      0.99      0.87      1165\n",
      "          3       0.74      0.39      0.51       241\n",
      "          4       0.67      0.18      0.28        67\n",
      "\n",
      "avg / total       0.76      0.77      0.73      1686\n",
      "\n",
      "[0/30] mean_loss : 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        50\n",
      "          1       0.55      0.58      0.56       219\n",
      "          2       0.87      0.93      0.90      1351\n",
      "          3       0.58      0.61      0.59       258\n",
      "          4       0.71      0.17      0.28        86\n",
      "\n",
      "avg / total       0.79      0.79      0.77      1964\n",
      "\n",
      "[0/30] mean_loss : 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.08        47\n",
      "          1       0.60      0.27      0.38       204\n",
      "          2       0.79      0.98      0.87      1383\n",
      "          3       0.76      0.38      0.51       256\n",
      "          4       1.00      0.11      0.20        54\n",
      "\n",
      "avg / total       0.78      0.78      0.74      1944\n",
      "\n",
      "[0/30] mean_loss : 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.07      0.12        45\n",
      "          1       0.64      0.48      0.55       216\n",
      "          2       0.85      0.96      0.90      1367\n",
      "          3       0.63      0.56      0.59       257\n",
      "          4       0.73      0.15      0.25        73\n",
      "\n",
      "avg / total       0.79      0.80      0.78      1958\n",
      "\n",
      "[0/30] mean_loss : 0.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.14        65\n",
      "          1       0.59      0.59      0.59       252\n",
      "          2       0.83      0.94      0.88      1312\n",
      "          3       0.62      0.45      0.52       256\n",
      "          4       0.64      0.13      0.21        71\n",
      "\n",
      "avg / total       0.77      0.77      0.75      1956\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.12      0.21        48\n",
      "          1       0.76      0.33      0.46       227\n",
      "          2       0.80      0.95      0.87      1238\n",
      "          3       0.61      0.54      0.57       257\n",
      "          4       0.62      0.25      0.36        40\n",
      "\n",
      "avg / total       0.76      0.77      0.75      1810\n",
      "\n",
      "[0/30] mean_loss : 0.60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.12      0.21        32\n",
      "          1       0.55      0.53      0.54       195\n",
      "          2       0.83      0.96      0.89      1301\n",
      "          3       0.81      0.39      0.53       249\n",
      "          4       0.92      0.22      0.35        55\n",
      "\n",
      "avg / total       0.80      0.80      0.77      1832\n",
      "\n",
      "[0/30] mean_loss : 0.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.14        62\n",
      "          1       0.65      0.50      0.57       202\n",
      "          2       0.87      0.92      0.90      1131\n",
      "          3       0.58      0.77      0.66       234\n",
      "          4       0.75      0.23      0.35        65\n",
      "\n",
      "avg / total       0.79      0.79      0.78      1694\n",
      "\n",
      "[0/30] mean_loss : 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.06      0.11        33\n",
      "          1       0.72      0.46      0.56       194\n",
      "          2       0.81      0.98      0.89      1211\n",
      "          3       0.70      0.39      0.50       215\n",
      "          4       0.80      0.19      0.31        63\n",
      "\n",
      "avg / total       0.79      0.80      0.77      1716\n",
      "\n",
      "[0/30] mean_loss : 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.06      0.11        69\n",
      "          1       0.51      0.77      0.61       244\n",
      "          2       0.92      0.90      0.91      1433\n",
      "          3       0.62      0.64      0.63       268\n",
      "          4       0.78      0.21      0.33        68\n",
      "\n",
      "avg / total       0.82      0.80      0.79      2082\n",
      "\n",
      "[0/30] mean_loss : 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16        34\n",
      "          1       0.64      0.23      0.33       191\n",
      "          2       0.80      0.97      0.88      1286\n",
      "          3       0.71      0.49      0.58       280\n",
      "          4       0.88      0.24      0.37        63\n",
      "\n",
      "avg / total       0.77      0.78      0.74      1854\n",
      "\n",
      "[0/30] mean_loss : 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.09      0.17        43\n",
      "          1       0.44      0.88      0.59       225\n",
      "          2       0.96      0.84      0.89      1362\n",
      "          3       0.62      0.71      0.66       280\n",
      "          4       0.88      0.21      0.34        70\n",
      "\n",
      "avg / total       0.85      0.79      0.79      1980\n",
      "\n",
      "[0/30] mean_loss : 0.68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.24        43\n",
      "          1       0.78      0.32      0.45       215\n",
      "          2       0.85      0.93      0.89      1250\n",
      "          3       0.52      0.74      0.61       296\n",
      "          4       0.68      0.15      0.24       102\n",
      "\n",
      "avg / total       0.78      0.77      0.75      1906\n",
      "\n",
      "[0/30] mean_loss : 0.62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.06      0.11        34\n",
      "          1       0.60      0.45      0.52       185\n",
      "          2       0.82      0.96      0.89      1211\n",
      "          3       0.66      0.47      0.55       281\n",
      "          4       0.85      0.16      0.28        67\n",
      "\n",
      "avg / total       0.77      0.79      0.76      1778\n",
      "\n",
      "[0/30] mean_loss : 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16        47\n",
      "          1       0.60      0.44      0.51       171\n",
      "          2       0.89      0.92      0.91      1294\n",
      "          3       0.52      0.72      0.60       277\n",
      "          4       0.78      0.25      0.38       113\n",
      "\n",
      "avg / total       0.80      0.79      0.78      1902\n",
      "\n",
      "[0/30] mean_loss : 0.60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.10      0.18        30\n",
      "          1       0.73      0.38      0.50       167\n",
      "          2       0.81      0.98      0.89      1344\n",
      "          3       0.72      0.39      0.51       269\n",
      "          4       0.69      0.13      0.22        70\n",
      "\n",
      "avg / total       0.79      0.80      0.76      1880\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.09      0.16        58\n",
      "          1       0.55      0.64      0.59       188\n",
      "          2       0.91      0.93      0.92      1340\n",
      "          3       0.60      0.68      0.64       229\n",
      "          4       0.67      0.20      0.31        49\n",
      "\n",
      "avg / total       0.83      0.82      0.81      1864\n",
      "\n",
      "[0/30] mean_loss : 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.06      0.11        34\n",
      "          1       0.65      0.37      0.47       166\n",
      "          2       0.85      0.96      0.90      1299\n",
      "          3       0.69      0.64      0.67       291\n",
      "          4       0.78      0.22      0.34        82\n",
      "\n",
      "avg / total       0.79      0.81      0.79      1872\n",
      "\n",
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.12      0.20        26\n",
      "          1       0.61      0.62      0.62       150\n",
      "          2       0.91      0.94      0.92      1187\n",
      "          3       0.60      0.59      0.60       263\n",
      "          4       0.60      0.51      0.55        98\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1724\n",
      "\n",
      "[0/30] mean_loss : 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.04      0.08        47\n",
      "          1       0.57      0.56      0.57       207\n",
      "          2       0.85      0.96      0.90      1221\n",
      "          3       0.71      0.49      0.58       224\n",
      "          4       0.86      0.32      0.46        57\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1756\n",
      "\n",
      "[0/30] mean_loss : 0.60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.16      0.27        62\n",
      "          1       0.59      0.75      0.66       218\n",
      "          2       0.93      0.90      0.91      1121\n",
      "          3       0.57      0.53      0.55       196\n",
      "          4       0.54      0.74      0.63        91\n",
      "\n",
      "avg / total       0.82      0.80      0.80      1688\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.10        20\n",
      "          1       0.84      0.25      0.38       187\n",
      "          2       0.82      0.99      0.89      1612\n",
      "          3       0.71      0.40      0.51       311\n",
      "          4       0.68      0.20      0.31        64\n",
      "\n",
      "avg / total       0.80      0.81      0.77      2194\n",
      "\n",
      "[0/30] mean_loss : 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.13      0.22        38\n",
      "          1       0.52      0.71      0.60       176\n",
      "          2       0.93      0.87      0.90      1255\n",
      "          3       0.58      0.81      0.68       251\n",
      "          4       0.76      0.24      0.37        66\n",
      "\n",
      "avg / total       0.83      0.80      0.80      1786\n",
      "\n",
      "[0/30] mean_loss : 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.16      0.27        44\n",
      "          1       0.60      0.55      0.57       222\n",
      "          2       0.84      0.95      0.89      1309\n",
      "          3       0.63      0.40      0.49       250\n",
      "          4       0.70      0.44      0.54        75\n",
      "\n",
      "avg / total       0.78      0.79      0.77      1900\n",
      "\n",
      "[0/30] mean_loss : 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.03      0.06        59\n",
      "          1       0.59      0.35      0.44       199\n",
      "          2       0.85      0.94      0.89      1322\n",
      "          3       0.64      0.72      0.68       299\n",
      "          4       0.61      0.25      0.36        67\n",
      "\n",
      "avg / total       0.78      0.79      0.77      1946\n",
      "\n",
      "[0/30] mean_loss : 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.24      0.36        51\n",
      "          1       0.55      0.53      0.54       195\n",
      "          2       0.86      0.94      0.90      1053\n",
      "          3       0.64      0.58      0.61       204\n",
      "          4       0.60      0.23      0.33        53\n",
      "\n",
      "avg / total       0.78      0.79      0.78      1556\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.08      0.15        49\n",
      "          1       0.63      0.43      0.51       195\n",
      "          2       0.87      0.95      0.91      1353\n",
      "          3       0.63      0.71      0.67       281\n",
      "          4       0.80      0.15      0.25        54\n",
      "\n",
      "avg / total       0.81      0.82      0.80      1932\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.08      0.14        77\n",
      "          1       0.50      0.58      0.54       206\n",
      "          2       0.88      0.93      0.91      1333\n",
      "          3       0.62      0.57      0.59       226\n",
      "          4       0.60      0.38      0.47        68\n",
      "\n",
      "avg / total       0.79      0.80      0.78      1910\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.12      0.21        40\n",
      "          1       0.66      0.59      0.62       212\n",
      "          2       0.88      0.94      0.91      1274\n",
      "          3       0.60      0.63      0.61       246\n",
      "          4       0.57      0.27      0.37        74\n",
      "\n",
      "avg / total       0.80      0.81      0.80      1846\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.04      0.07        26\n",
      "          1       0.62      0.60      0.61       192\n",
      "          2       0.87      0.94      0.91      1155\n",
      "          3       0.70      0.65      0.67       224\n",
      "          4       0.93      0.35      0.51        71\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1668\n",
      "\n",
      "[0/30] mean_loss : 0.60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.17      0.28        63\n",
      "          1       0.50      0.76      0.60       241\n",
      "          2       0.89      0.89      0.89      1180\n",
      "          3       0.71      0.50      0.59       197\n",
      "          4       0.67      0.46      0.55        69\n",
      "\n",
      "avg / total       0.80      0.79      0.78      1750\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.11      0.19        47\n",
      "          1       0.64      0.49      0.55       204\n",
      "          2       0.87      0.93      0.90      1420\n",
      "          3       0.62      0.69      0.65       313\n",
      "          4       0.64      0.23      0.33        62\n",
      "\n",
      "avg / total       0.80      0.81      0.80      2046\n",
      "\n",
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.08        46\n",
      "          1       0.52      0.56      0.54       189\n",
      "          2       0.90      0.94      0.92      1330\n",
      "          3       0.65      0.63      0.64       203\n",
      "          4       0.64      0.43      0.52        90\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1858\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.17      0.27        40\n",
      "          1       0.67      0.53      0.59       180\n",
      "          2       0.90      0.91      0.91      1278\n",
      "          3       0.59      0.76      0.67       293\n",
      "          4       0.62      0.36      0.45        81\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1872\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.09      0.16        54\n",
      "          1       0.53      0.72      0.62       258\n",
      "          2       0.89      0.92      0.91      1339\n",
      "          3       0.66      0.54      0.60       245\n",
      "          4       0.86      0.22      0.35        54\n",
      "\n",
      "avg / total       0.81      0.80      0.79      1950\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.12      0.21        50\n",
      "          1       0.62      0.46      0.53       238\n",
      "          2       0.85      0.96      0.90      1484\n",
      "          3       0.68      0.56      0.61       278\n",
      "          4       0.79      0.51      0.62       104\n",
      "\n",
      "avg / total       0.80      0.81      0.79      2154\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.20      0.33        20\n",
      "          1       0.80      0.47      0.59       183\n",
      "          2       0.90      0.94      0.92      1479\n",
      "          3       0.62      0.73      0.67       300\n",
      "          4       0.57      0.39      0.46        96\n",
      "\n",
      "avg / total       0.84      0.84      0.83      2078\n",
      "\n",
      "[0/30] mean_loss : 0.60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.12      0.22        72\n",
      "          1       0.55      0.72      0.62       263\n",
      "          2       0.88      0.93      0.90      1337\n",
      "          3       0.70      0.50      0.58       230\n",
      "          4       0.76      0.26      0.39        50\n",
      "\n",
      "avg / total       0.81      0.80      0.79      1952\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.07      0.12        28\n",
      "          1       0.66      0.74      0.70       239\n",
      "          2       0.91      0.90      0.91      1229\n",
      "          3       0.63      0.74      0.68       254\n",
      "          4       0.80      0.27      0.40        60\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1810\n",
      "\n",
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.13      0.22        55\n",
      "          1       0.60      0.59      0.60       239\n",
      "          2       0.86      0.94      0.90      1310\n",
      "          3       0.67      0.60      0.64       237\n",
      "          4       0.76      0.33      0.46        67\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1908\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.11      0.18        47\n",
      "          1       0.61      0.57      0.59       200\n",
      "          2       0.89      0.94      0.91      1335\n",
      "          3       0.63      0.63      0.63       258\n",
      "          4       0.64      0.47      0.55        80\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1920\n",
      "\n",
      "[0/30] mean_loss : 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.09      0.15        58\n",
      "          1       0.52      0.49      0.51       203\n",
      "          2       0.86      0.93      0.89      1269\n",
      "          3       0.59      0.55      0.57       228\n",
      "          4       0.72      0.55      0.62        78\n",
      "\n",
      "avg / total       0.78      0.79      0.78      1836\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.15      0.24        34\n",
      "          1       0.63      0.38      0.48       139\n",
      "          2       0.89      0.94      0.91      1355\n",
      "          3       0.63      0.73      0.67       310\n",
      "          4       0.75      0.27      0.40        78\n",
      "\n",
      "avg / total       0.82      0.83      0.81      1916\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.25        49\n",
      "          1       0.54      0.48      0.51       216\n",
      "          2       0.87      0.95      0.91      1556\n",
      "          3       0.69      0.61      0.65       317\n",
      "          4       0.59      0.20      0.30        64\n",
      "\n",
      "avg / total       0.80      0.81      0.80      2202\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.15      0.26        46\n",
      "          1       0.56      0.78      0.65       255\n",
      "          2       0.91      0.90      0.91      1316\n",
      "          3       0.68      0.64      0.66       265\n",
      "          4       0.82      0.31      0.45        58\n",
      "\n",
      "avg / total       0.83      0.82      0.81      1940\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.11      0.18        27\n",
      "          1       0.66      0.37      0.48       195\n",
      "          2       0.89      0.92      0.91      1287\n",
      "          3       0.58      0.74      0.65       278\n",
      "          4       0.68      0.55      0.61       107\n",
      "\n",
      "avg / total       0.80      0.81      0.80      1894\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.10      0.17        41\n",
      "          1       0.66      0.49      0.56       176\n",
      "          2       0.85      0.96      0.90      1306\n",
      "          3       0.68      0.55      0.61       280\n",
      "          4       0.88      0.29      0.44        75\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1878\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.10      0.16        70\n",
      "          1       0.48      0.75      0.58       238\n",
      "          2       0.92      0.88      0.90      1338\n",
      "          3       0.65      0.65      0.65       270\n",
      "          4       0.77      0.44      0.56        62\n",
      "\n",
      "avg / total       0.81      0.79      0.79      1978\n",
      "\n",
      "[0/30] mean_loss : 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.12      0.21        33\n",
      "          1       0.70      0.52      0.59       191\n",
      "          2       0.85      0.96      0.90      1211\n",
      "          3       0.68      0.62      0.65       234\n",
      "          4       0.96      0.32      0.47        73\n",
      "\n",
      "avg / total       0.82      0.82      0.80      1742\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.07      0.12        45\n",
      "          1       0.59      0.53      0.56       179\n",
      "          2       0.89      0.93      0.91      1245\n",
      "          3       0.64      0.78      0.70       320\n",
      "          4       0.76      0.27      0.39        83\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1872\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.11      0.21        35\n",
      "          1       0.69      0.52      0.59       167\n",
      "          2       0.87      0.95      0.91      1261\n",
      "          3       0.65      0.63      0.64       273\n",
      "          4       0.88      0.34      0.49        62\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1798\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.12        30\n",
      "          1       0.53      0.52      0.53       191\n",
      "          2       0.86      0.94      0.90      1267\n",
      "          3       0.66      0.53      0.59       236\n",
      "          4       0.94      0.30      0.46        56\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1780\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.05      0.10        55\n",
      "          1       0.56      0.52      0.54       198\n",
      "          2       0.87      0.93      0.90      1331\n",
      "          3       0.60      0.64      0.61       285\n",
      "          4       0.86      0.26      0.40        69\n",
      "\n",
      "avg / total       0.79      0.80      0.78      1938\n",
      "\n",
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.13      0.22        47\n",
      "          1       0.63      0.58      0.60       210\n",
      "          2       0.88      0.95      0.91      1473\n",
      "          3       0.63      0.65      0.64       293\n",
      "          4       0.89      0.18      0.30        93\n",
      "\n",
      "avg / total       0.82      0.82      0.80      2116\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.11      0.19        61\n",
      "          1       0.53      0.58      0.56       201\n",
      "          2       0.90      0.93      0.91      1300\n",
      "          3       0.65      0.72      0.68       245\n",
      "          4       0.72      0.23      0.35        57\n",
      "\n",
      "avg / total       0.81      0.82      0.80      1864\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.17      0.29        47\n",
      "          1       0.60      0.45      0.52       196\n",
      "          2       0.87      0.95      0.91      1405\n",
      "          3       0.65      0.62      0.63       262\n",
      "          4       0.85      0.25      0.39        44\n",
      "\n",
      "avg / total       0.81      0.82      0.80      1954\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.25      0.36        40\n",
      "          1       0.63      0.45      0.53       157\n",
      "          2       0.88      0.95      0.92      1285\n",
      "          3       0.65      0.61      0.63       239\n",
      "          4       0.67      0.45      0.54        73\n",
      "\n",
      "avg / total       0.81      0.83      0.82      1794\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.22      0.34        63\n",
      "          1       0.56      0.76      0.65       196\n",
      "          2       0.91      0.93      0.92      1238\n",
      "          3       0.72      0.62      0.67       219\n",
      "          4       0.76      0.47      0.58        66\n",
      "\n",
      "avg / total       0.84      0.83      0.83      1782\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.03      0.06        29\n",
      "          1       0.62      0.51      0.56       188\n",
      "          2       0.89      0.94      0.92      1386\n",
      "          3       0.69      0.75      0.72       302\n",
      "          4       0.78      0.27      0.40        67\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1972\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.17      0.28        54\n",
      "          1       0.66      0.71      0.68       205\n",
      "          2       0.91      0.94      0.92      1170\n",
      "          3       0.70      0.71      0.71       219\n",
      "          4       0.81      0.31      0.45        42\n",
      "\n",
      "avg / total       0.85      0.84      0.83      1690\n",
      "\n",
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.15      0.25        60\n",
      "          1       0.67      0.58      0.62       208\n",
      "          2       0.86      0.96      0.91      1370\n",
      "          3       0.68      0.52      0.59       267\n",
      "          4       0.83      0.41      0.55        59\n",
      "\n",
      "avg / total       0.81      0.82      0.80      1964\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.15      0.24        39\n",
      "          1       0.64      0.68      0.66       187\n",
      "          2       0.92      0.89      0.91      1318\n",
      "          3       0.59      0.77      0.67       325\n",
      "          4       0.78      0.28      0.41        75\n",
      "\n",
      "avg / total       0.82      0.81      0.81      1944\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.13      0.22        39\n",
      "          1       0.63      0.54      0.58       157\n",
      "          2       0.89      0.95      0.92      1307\n",
      "          3       0.67      0.58      0.62       276\n",
      "          4       0.63      0.61      0.62       113\n",
      "\n",
      "avg / total       0.82      0.83      0.81      1892\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.18      0.26        84\n",
      "          1       0.49      0.76      0.59       210\n",
      "          2       0.93      0.90      0.92      1275\n",
      "          3       0.66      0.52      0.58       226\n",
      "          4       0.50      0.60      0.54        83\n",
      "\n",
      "avg / total       0.81      0.80      0.80      1878\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.13      0.21        67\n",
      "          1       0.62      0.57      0.59       222\n",
      "          2       0.88      0.95      0.91      1282\n",
      "          3       0.65      0.69      0.67       292\n",
      "          4       0.78      0.30      0.43        93\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1956\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.24      0.35        45\n",
      "          1       0.61      0.66      0.63       154\n",
      "          2       0.90      0.95      0.92      1015\n",
      "          3       0.66      0.65      0.66       238\n",
      "          4       0.78      0.34      0.47        74\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1526\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.13      0.22        52\n",
      "          1       0.53      0.51      0.52       197\n",
      "          2       0.87      0.95      0.91      1262\n",
      "          3       0.67      0.62      0.64       228\n",
      "          4       0.77      0.33      0.47        81\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1820\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.17      0.28        58\n",
      "          1       0.59      0.56      0.58       197\n",
      "          2       0.88      0.92      0.90      1104\n",
      "          3       0.67      0.77      0.71       257\n",
      "          4       0.81      0.33      0.47        66\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1682\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.10        40\n",
      "          1       0.69      0.45      0.55       233\n",
      "          2       0.87      0.94      0.90      1480\n",
      "          3       0.65      0.69      0.67       291\n",
      "          4       0.81      0.45      0.58        38\n",
      "\n",
      "avg / total       0.82      0.82      0.81      2082\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.08      0.15        49\n",
      "          1       0.54      0.75      0.63       217\n",
      "          2       0.91      0.93      0.92      1334\n",
      "          3       0.69      0.65      0.67       281\n",
      "          4       0.79      0.41      0.54        93\n",
      "\n",
      "avg / total       0.83      0.82      0.82      1974\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.10      0.17        61\n",
      "          1       0.61      0.53      0.57       223\n",
      "          2       0.87      0.96      0.92      1283\n",
      "          3       0.74      0.68      0.71       258\n",
      "          4       0.77      0.21      0.33        47\n",
      "\n",
      "avg / total       0.81      0.83      0.81      1872\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.15      0.25        67\n",
      "          1       0.55      0.64      0.59       234\n",
      "          2       0.89      0.95      0.92      1520\n",
      "          3       0.75      0.56      0.64       262\n",
      "          4       0.84      0.41      0.55        39\n",
      "\n",
      "avg / total       0.83      0.83      0.82      2122\n",
      "\n",
      "[0/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.28      0.43        46\n",
      "          1       0.60      0.69      0.64       178\n",
      "          2       0.92      0.93      0.92      1312\n",
      "          3       0.65      0.77      0.71       346\n",
      "          4       0.94      0.20      0.32        82\n",
      "\n",
      "avg / total       0.85      0.83      0.82      1964\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        51\n",
      "          1       0.59      0.70      0.64       218\n",
      "          2       0.90      0.94      0.92      1281\n",
      "          3       0.66      0.62      0.64       230\n",
      "          4       0.75      0.39      0.51        70\n",
      "\n",
      "avg / total       0.83      0.83      0.81      1850\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.20      0.33        35\n",
      "          1       0.58      0.66      0.62       153\n",
      "          2       0.91      0.91      0.91      1111\n",
      "          3       0.63      0.69      0.66       258\n",
      "          4       0.53      0.39      0.45        67\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1624\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.18      0.29        55\n",
      "          1       0.62      0.63      0.62       196\n",
      "          2       0.91      0.94      0.92      1173\n",
      "          3       0.59      0.69      0.64       217\n",
      "          4       0.74      0.48      0.58        81\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1722\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.20      0.30        74\n",
      "          1       0.56      0.50      0.53       199\n",
      "          2       0.88      0.95      0.91      1285\n",
      "          3       0.63      0.66      0.65       248\n",
      "          4       0.55      0.25      0.34        68\n",
      "\n",
      "avg / total       0.79      0.81      0.79      1874\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.11      0.19        35\n",
      "          1       0.59      0.45      0.51       169\n",
      "          2       0.85      0.95      0.90      1165\n",
      "          3       0.68      0.58      0.63       259\n",
      "          4       0.80      0.34      0.48        58\n",
      "\n",
      "avg / total       0.79      0.81      0.79      1686\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.35      0.45        43\n",
      "          1       0.56      0.56      0.56       201\n",
      "          2       0.87      0.92      0.90      1171\n",
      "          3       0.68      0.58      0.62       241\n",
      "          4       0.75      0.46      0.57        46\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1702\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.07      0.13        40\n",
      "          1       0.61      0.50      0.55       198\n",
      "          2       0.89      0.94      0.91      1381\n",
      "          3       0.63      0.69      0.66       293\n",
      "          4       0.81      0.39      0.53        64\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1976\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.27      0.36        77\n",
      "          1       0.58      0.86      0.69       257\n",
      "          2       0.94      0.90      0.92      1105\n",
      "          3       0.69      0.63      0.66       217\n",
      "          4       0.61      0.38      0.47        58\n",
      "\n",
      "avg / total       0.82      0.81      0.81      1714\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.31      0.44        48\n",
      "          1       0.65      0.41      0.50       180\n",
      "          2       0.85      0.96      0.90      1198\n",
      "          3       0.62      0.51      0.56       257\n",
      "          4       0.75      0.64      0.69       121\n",
      "\n",
      "avg / total       0.79      0.80      0.79      1804\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.47      0.61        47\n",
      "          1       0.58      0.55      0.57       192\n",
      "          2       0.87      0.95      0.91      1401\n",
      "          3       0.69      0.58      0.63       318\n",
      "          4       0.68      0.31      0.43        86\n",
      "\n",
      "avg / total       0.81      0.82      0.81      2044\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.29      0.42        58\n",
      "          1       0.51      0.63      0.56       191\n",
      "          2       0.92      0.91      0.91      1250\n",
      "          3       0.61      0.67      0.64       252\n",
      "          4       0.54      0.40      0.46        67\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1818\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.09      0.15        45\n",
      "          1       0.59      0.40      0.47       197\n",
      "          2       0.84      0.97      0.90      1383\n",
      "          3       0.64      0.48      0.55       277\n",
      "          4       0.71      0.38      0.50        66\n",
      "\n",
      "avg / total       0.78      0.80      0.78      1968\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.16      0.25        67\n",
      "          1       0.54      0.56      0.55       204\n",
      "          2       0.89      0.92      0.90      1253\n",
      "          3       0.64      0.70      0.67       250\n",
      "          4       0.74      0.44      0.55        70\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1844\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.15      0.26        33\n",
      "          1       0.56      0.71      0.62       213\n",
      "          2       0.90      0.92      0.91      1294\n",
      "          3       0.67      0.64      0.66       243\n",
      "          4       0.69      0.27      0.39        67\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1850\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.16      0.24        45\n",
      "          1       0.51      0.54      0.52       179\n",
      "          2       0.89      0.94      0.91      1299\n",
      "          3       0.69      0.65      0.67       266\n",
      "          4       0.74      0.54      0.62        93\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1882\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.12      0.20        40\n",
      "          1       0.52      0.56      0.54       171\n",
      "          2       0.90      0.90      0.90      1274\n",
      "          3       0.61      0.77      0.68       312\n",
      "          4       0.78      0.36      0.49       101\n",
      "\n",
      "avg / total       0.81      0.80      0.79      1898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.14        25\n",
      "          1       0.62      0.56      0.59       173\n",
      "          2       0.88      0.96      0.92      1152\n",
      "          3       0.68      0.55      0.61       208\n",
      "          4       0.73      0.44      0.55        68\n",
      "\n",
      "avg / total       0.81      0.83      0.81      1626\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.34      0.48        58\n",
      "          1       0.58      0.61      0.60       194\n",
      "          2       0.90      0.91      0.91      1187\n",
      "          3       0.64      0.70      0.67       262\n",
      "          4       0.62      0.23      0.33        35\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1736\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.14      0.23        64\n",
      "          1       0.54      0.65      0.59       228\n",
      "          2       0.88      0.93      0.90      1302\n",
      "          3       0.73      0.65      0.69       280\n",
      "          4       0.78      0.26      0.40        68\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1942\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.24      0.37        38\n",
      "          1       0.64      0.52      0.57       172\n",
      "          2       0.90      0.93      0.91      1094\n",
      "          3       0.63      0.82      0.71       257\n",
      "          4       0.89      0.31      0.46        77\n",
      "\n",
      "avg / total       0.83      0.82      0.81      1638\n",
      "\n",
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.18      0.30        66\n",
      "          1       0.53      0.63      0.58       220\n",
      "          2       0.89      0.93      0.91      1224\n",
      "          3       0.72      0.63      0.67       255\n",
      "          4       0.75      0.47      0.58        51\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1816\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.35      0.45        54\n",
      "          1       0.65      0.53      0.58       171\n",
      "          2       0.89      0.95      0.92      1229\n",
      "          3       0.66      0.67      0.66       245\n",
      "          4       0.68      0.47      0.56        99\n",
      "\n",
      "avg / total       0.81      0.82      0.82      1798\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.25      0.34        57\n",
      "          1       0.53      0.61      0.56       218\n",
      "          2       0.89      0.93      0.91      1334\n",
      "          3       0.68      0.57      0.62       248\n",
      "          4       0.59      0.41      0.48        59\n",
      "\n",
      "avg / total       0.80      0.81      0.80      1916\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.18      0.28        56\n",
      "          1       0.66      0.61      0.64       232\n",
      "          2       0.87      0.95      0.91      1244\n",
      "          3       0.73      0.62      0.67       250\n",
      "          4       0.81      0.57      0.67        46\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1828\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.38      0.43        80\n",
      "          1       0.57      0.61      0.59       201\n",
      "          2       0.90      0.92      0.91      1227\n",
      "          3       0.64      0.68      0.66       255\n",
      "          4       0.74      0.35      0.48        71\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1834\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.19      0.29        57\n",
      "          1       0.57      0.61      0.59       247\n",
      "          2       0.87      0.94      0.90      1374\n",
      "          3       0.68      0.52      0.59       247\n",
      "          4       0.72      0.40      0.51        83\n",
      "\n",
      "avg / total       0.79      0.80      0.79      2008\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.13      0.23        30\n",
      "          1       0.61      0.69      0.65       198\n",
      "          2       0.91      0.93      0.92      1247\n",
      "          3       0.64      0.58      0.61       196\n",
      "          4       0.64      0.58      0.61        81\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1752\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.17      0.28        58\n",
      "          1       0.68      0.56      0.62       217\n",
      "          2       0.87      0.97      0.92      1285\n",
      "          3       0.70      0.53      0.60       201\n",
      "          4       0.75      0.38      0.51        47\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1808\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.12      0.19        59\n",
      "          1       0.54      0.82      0.65       258\n",
      "          2       0.93      0.89      0.91      1212\n",
      "          3       0.73      0.60      0.66       184\n",
      "          4       0.76      0.73      0.74        51\n",
      "\n",
      "avg / total       0.83      0.82      0.81      1764\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.15      0.25        53\n",
      "          1       0.67      0.53      0.59       232\n",
      "          2       0.88      0.96      0.92      1465\n",
      "          3       0.66      0.69      0.67       291\n",
      "          4       0.88      0.28      0.43        81\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2122\n",
      "\n",
      "[0/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.08      0.13        39\n",
      "          1       0.62      0.69      0.65       190\n",
      "          2       0.93      0.93      0.93      1316\n",
      "          3       0.69      0.81      0.74       264\n",
      "          4       0.77      0.43      0.55        77\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1886\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.12      0.21        59\n",
      "          1       0.61      0.69      0.65       203\n",
      "          2       0.90      0.94      0.92      1425\n",
      "          3       0.66      0.62      0.64       312\n",
      "          4       0.61      0.43      0.51        83\n",
      "\n",
      "avg / total       0.82      0.82      0.81      2082\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.13      0.22        39\n",
      "          1       0.55      0.75      0.63       195\n",
      "          2       0.91      0.92      0.92      1285\n",
      "          3       0.67      0.59      0.63       235\n",
      "          4       0.75      0.60      0.66        94\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1848\n",
      "\n",
      "[0/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.24      0.39        29\n",
      "          1       0.71      0.45      0.55       194\n",
      "          2       0.89      0.95      0.92      1359\n",
      "          3       0.62      0.72      0.67       253\n",
      "          4       0.85      0.40      0.54        73\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1908\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21        52\n",
      "          1       0.60      0.70      0.65       212\n",
      "          2       0.89      0.95      0.92      1252\n",
      "          3       0.77      0.57      0.65       244\n",
      "          4       0.71      0.33      0.45        46\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1806\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.10      0.18        29\n",
      "          1       0.70      0.68      0.69       222\n",
      "          2       0.90      0.93      0.92      1374\n",
      "          3       0.65      0.69      0.67       268\n",
      "          4       0.76      0.35      0.47        55\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1948\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.26      0.39        39\n",
      "          1       0.65      0.65      0.65       214\n",
      "          2       0.90      0.91      0.90      1246\n",
      "          3       0.58      0.65      0.62       223\n",
      "          4       0.70      0.40      0.51        58\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1780\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.07      0.13        42\n",
      "          1       0.60      0.61      0.61       178\n",
      "          2       0.90      0.92      0.91      1095\n",
      "          3       0.66      0.74      0.70       305\n",
      "          4       0.62      0.50      0.55        84\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1704\n",
      "\n",
      "[0/30] mean_loss : 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.16        47\n",
      "          1       0.66      0.69      0.68       215\n",
      "          2       0.88      0.95      0.91      1364\n",
      "          3       0.57      0.47      0.51       268\n",
      "          4       0.57      0.38      0.46        92\n",
      "\n",
      "avg / total       0.80      0.81      0.79      1986\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.13      0.23        60\n",
      "          1       0.58      0.65      0.61       217\n",
      "          2       0.90      0.94      0.92      1382\n",
      "          3       0.64      0.65      0.64       270\n",
      "          4       0.64      0.30      0.41        77\n",
      "\n",
      "avg / total       0.81      0.82      0.81      2006\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.11      0.19        38\n",
      "          1       0.61      0.57      0.59       202\n",
      "          2       0.89      0.94      0.91      1323\n",
      "          3       0.65      0.69      0.67       277\n",
      "          4       0.75      0.38      0.50        80\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1920\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.05      0.10        37\n",
      "          1       0.66      0.58      0.62       202\n",
      "          2       0.87      0.95      0.91      1284\n",
      "          3       0.62      0.55      0.58       263\n",
      "          4       0.72      0.36      0.48        80\n",
      "\n",
      "avg / total       0.80      0.81      0.80      1866\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.36      0.48        83\n",
      "          1       0.57      0.61      0.59       209\n",
      "          2       0.89      0.94      0.91      1240\n",
      "          3       0.66      0.59      0.62       213\n",
      "          4       0.71      0.58      0.64        67\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1812\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.30      0.41        33\n",
      "          1       0.57      0.61      0.59       159\n",
      "          2       0.89      0.94      0.91      1088\n",
      "          3       0.72      0.58      0.64       214\n",
      "          4       0.61      0.35      0.44        40\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1534\n",
      "\n",
      "[0/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.27      0.37        67\n",
      "          1       0.64      0.67      0.66       225\n",
      "          2       0.90      0.95      0.92      1298\n",
      "          3       0.71      0.57      0.63       188\n",
      "          4       0.83      0.56      0.67        36\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1814\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.20      0.33        45\n",
      "          1       0.65      0.48      0.55       173\n",
      "          2       0.88      0.96      0.92      1389\n",
      "          3       0.65      0.61      0.63       230\n",
      "          4       0.79      0.44      0.56        71\n",
      "\n",
      "avg / total       0.83      0.84      0.82      1908\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.21      0.34        47\n",
      "          1       0.60      0.68      0.64       224\n",
      "          2       0.91      0.92      0.91      1359\n",
      "          3       0.65      0.70      0.67       285\n",
      "          4       0.78      0.39      0.52        79\n",
      "\n",
      "avg / total       0.83      0.82      0.82      1994\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.36      0.44        64\n",
      "          1       0.63      0.63      0.63       209\n",
      "          2       0.89      0.93      0.91      1248\n",
      "          3       0.67      0.66      0.67       299\n",
      "          4       0.70      0.43      0.53        86\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1906\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.23      0.33        47\n",
      "          1       0.60      0.65      0.62       155\n",
      "          2       0.90      0.96      0.93      1184\n",
      "          3       0.71      0.61      0.65       238\n",
      "          4       0.74      0.51      0.60        76\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1700\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.14      0.24        36\n",
      "          1       0.62      0.72      0.67       218\n",
      "          2       0.90      0.92      0.91      1208\n",
      "          3       0.66      0.68      0.67       287\n",
      "          4       0.76      0.32      0.45        79\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1828\n",
      "\n",
      "[0/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.24      0.36        33\n",
      "          1       0.60      0.59      0.60       169\n",
      "          2       0.91      0.93      0.92      1253\n",
      "          3       0.58      0.67      0.62       234\n",
      "          4       0.73      0.47      0.57        85\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1774\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.16      0.26        25\n",
      "          1       0.63      0.54      0.59       158\n",
      "          2       0.88      0.96      0.92      1153\n",
      "          3       0.69      0.62      0.65       239\n",
      "          4       0.82      0.42      0.55        77\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1652\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.07      0.12        57\n",
      "          1       0.59      0.75      0.66       204\n",
      "          2       0.90      0.92      0.91      1216\n",
      "          3       0.67      0.58      0.62       208\n",
      "          4       0.49      0.37      0.42        49\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1734\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.08      0.14        39\n",
      "          1       0.64      0.59      0.61       174\n",
      "          2       0.91      0.96      0.93      1159\n",
      "          3       0.65      0.73      0.69       265\n",
      "          4       0.70      0.36      0.47        89\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1726\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.16      0.27        43\n",
      "          1       0.56      0.77      0.65       181\n",
      "          2       0.91      0.92      0.92      1174\n",
      "          3       0.67      0.64      0.65       259\n",
      "          4       0.76      0.44      0.55       101\n",
      "\n",
      "avg / total       0.83      0.82      0.81      1758\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.20      0.33        44\n",
      "          1       0.64      0.53      0.58       212\n",
      "          2       0.85      0.96      0.90      1156\n",
      "          3       0.70      0.50      0.58       179\n",
      "          4       0.85      0.55      0.67        51\n",
      "\n",
      "avg / total       0.81      0.82      0.80      1642\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.17        42\n",
      "          1       0.54      0.80      0.64       230\n",
      "          2       0.92      0.90      0.91      1341\n",
      "          3       0.70      0.61      0.65       224\n",
      "          4       0.82      0.51      0.63        61\n",
      "\n",
      "avg / total       0.84      0.82      0.82      1898\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21        34\n",
      "          1       0.65      0.50      0.56       214\n",
      "          2       0.87      0.95      0.91      1354\n",
      "          3       0.65      0.62      0.64       245\n",
      "          4       0.62      0.29      0.39        63\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1910\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.21      0.33        43\n",
      "          1       0.67      0.65      0.66       205\n",
      "          2       0.90      0.95      0.92      1220\n",
      "          3       0.70      0.67      0.68       248\n",
      "          4       0.70      0.52      0.60        86\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1802\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.10      0.17        31\n",
      "          1       0.62      0.64      0.63       220\n",
      "          2       0.88      0.94      0.91      1411\n",
      "          3       0.68      0.56      0.62       282\n",
      "          4       0.76      0.38      0.51        68\n",
      "\n",
      "avg / total       0.81      0.82      0.81      2012\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.17      0.28        59\n",
      "          1       0.62      0.63      0.63       215\n",
      "          2       0.89      0.95      0.92      1250\n",
      "          3       0.66      0.61      0.63       224\n",
      "          4       0.72      0.44      0.55        66\n",
      "\n",
      "avg / total       0.82      0.83      0.81      1814\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.15      0.26        26\n",
      "          1       0.61      0.61      0.61       205\n",
      "          2       0.91      0.90      0.90      1349\n",
      "          3       0.64      0.75      0.69       362\n",
      "          4       0.65      0.45      0.53        78\n",
      "\n",
      "avg / total       0.82      0.81      0.81      2020\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.56      0.59        90\n",
      "          1       0.62      0.57      0.60       186\n",
      "          2       0.89      0.96      0.92      1231\n",
      "          3       0.67      0.57      0.61       252\n",
      "          4       0.69      0.33      0.45        75\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1834\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.15      0.24        47\n",
      "          1       0.66      0.66      0.66       174\n",
      "          2       0.92      0.92      0.92      1254\n",
      "          3       0.61      0.77      0.69       266\n",
      "          4       0.55      0.25      0.35        63\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1804\n",
      "\n",
      "[0/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.34      0.45        50\n",
      "          1       0.61      0.65      0.63       167\n",
      "          2       0.91      0.94      0.92      1166\n",
      "          3       0.66      0.60      0.63       242\n",
      "          4       0.69      0.69      0.69       101\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1726\n",
      "\n",
      "[0/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.09      0.16        43\n",
      "          1       0.63      0.56      0.60       179\n",
      "          2       0.89      0.94      0.91      1326\n",
      "          3       0.71      0.72      0.72       307\n",
      "          4       0.92      0.39      0.55        61\n",
      "\n",
      "avg / total       0.83      0.84      0.82      1916\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18        50\n",
      "          1       0.54      0.67      0.60       210\n",
      "          2       0.90      0.92      0.91      1205\n",
      "          3       0.70      0.68      0.69       261\n",
      "          4       0.66      0.42      0.51        64\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1790\n",
      "\n",
      "[0/30] mean_loss : 0.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.23      0.37        31\n",
      "          1       0.64      0.41      0.50       165\n",
      "          2       0.88      0.95      0.92      1280\n",
      "          3       0.67      0.73      0.70       267\n",
      "          4       0.86      0.40      0.55        75\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1818\n",
      "\n",
      "[0/30] mean_loss : 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.18      0.29        61\n",
      "          1       0.53      0.73      0.61       220\n",
      "          2       0.90      0.92      0.91      1175\n",
      "          3       0.67      0.57      0.62       232\n",
      "          4       0.63      0.45      0.52        82\n",
      "\n",
      "avg / total       0.81      0.80      0.79      1770\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.31      0.44        39\n",
      "          1       0.73      0.55      0.63       204\n",
      "          2       0.87      0.94      0.91      1245\n",
      "          3       0.63      0.67      0.65       245\n",
      "          4       0.74      0.31      0.43        65\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1798\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.40      0.50        70\n",
      "          1       0.62      0.71      0.66       268\n",
      "          2       0.92      0.92      0.92      1400\n",
      "          3       0.66      0.74      0.69       266\n",
      "          4       0.63      0.27      0.37        64\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2068\n",
      "\n",
      "[0/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.19      0.31        42\n",
      "          1       0.68      0.60      0.64       197\n",
      "          2       0.91      0.94      0.93      1305\n",
      "          3       0.69      0.80      0.74       311\n",
      "          4       0.91      0.30      0.46        69\n",
      "\n",
      "avg / total       0.85      0.85      0.84      1924\n",
      "\n",
      "[0/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.13      0.23        39\n",
      "          1       0.62      0.60      0.61       210\n",
      "          2       0.87      0.96      0.91      1348\n",
      "          3       0.74      0.52      0.61       245\n",
      "          4       0.91      0.33      0.49        30\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1872\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.30      0.44        40\n",
      "          1       0.64      0.66      0.65       210\n",
      "          2       0.92      0.93      0.92      1257\n",
      "          3       0.65      0.76      0.70       259\n",
      "          4       0.73      0.31      0.43        62\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1828\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.18      0.29        51\n",
      "          1       0.58      0.61      0.60       222\n",
      "          2       0.89      0.93      0.91      1325\n",
      "          3       0.68      0.67      0.68       285\n",
      "          4       0.79      0.45      0.57        85\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1968\n",
      "\n",
      "[0/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.20      0.32        60\n",
      "          1       0.56      0.75      0.64       218\n",
      "          2       0.91      0.91      0.91      1384\n",
      "          3       0.68      0.72      0.70       315\n",
      "          4       0.85      0.26      0.40        65\n",
      "\n",
      "avg / total       0.83      0.82      0.81      2042\n",
      "\n",
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.25      0.38        53\n",
      "          1       0.64      0.69      0.66       210\n",
      "          2       0.90      0.94      0.92      1244\n",
      "          3       0.66      0.65      0.66       248\n",
      "          4       0.63      0.35      0.45        89\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1844\n",
      "\n",
      "[0/30] mean_loss : 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.28      0.43        46\n",
      "          1       0.67      0.49      0.57       182\n",
      "          2       0.87      0.95      0.91      1351\n",
      "          3       0.65      0.64      0.65       312\n",
      "          4       0.70      0.42      0.52        89\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1980\n",
      "\n",
      "[0/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.22      0.34        27\n",
      "          1       0.66      0.56      0.61       173\n",
      "          2       0.90      0.96      0.93      1285\n",
      "          3       0.65      0.57      0.61       232\n",
      "          4       0.58      0.42      0.49        59\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1776\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.17      0.29        58\n",
      "          1       0.60      0.68      0.64       208\n",
      "          2       0.88      0.93      0.90      1435\n",
      "          3       0.68      0.63      0.66       301\n",
      "          4       0.94      0.31      0.46        52\n",
      "\n",
      "avg / total       0.82      0.82      0.81      2054\n",
      "\n",
      "[0/30] mean_loss : 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.49      0.58        71\n",
      "          1       0.57      0.41      0.48       176\n",
      "          2       0.85      0.95      0.90      1173\n",
      "          3       0.68      0.61      0.64       265\n",
      "          4       0.78      0.29      0.42        49\n",
      "\n",
      "avg / total       0.79      0.80      0.79      1734\n",
      "\n",
      "[0/30] mean_loss : 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.20      0.29        49\n",
      "          1       0.56      0.76      0.65       195\n",
      "          2       0.93      0.92      0.93      1142\n",
      "          3       0.74      0.69      0.72       213\n",
      "          4       0.79      0.51      0.62        45\n",
      "\n",
      "avg / total       0.85      0.84      0.84      1644\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.14      0.24        43\n",
      "          1       0.61      0.41      0.49       176\n",
      "          2       0.87      0.97      0.92      1338\n",
      "          3       0.72      0.66      0.69       284\n",
      "          4       0.78      0.46      0.58        87\n",
      "\n",
      "avg / total       0.82      0.83      0.81      1928\n",
      "\n",
      "[1/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.33      0.43        54\n",
      "          1       0.67      0.71      0.69       211\n",
      "          2       0.90      0.94      0.92      1088\n",
      "          3       0.69      0.70      0.70       248\n",
      "          4       0.76      0.42      0.54        77\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1678\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.28      0.42        53\n",
      "          1       0.64      0.67      0.65       185\n",
      "          2       0.91      0.94      0.93      1228\n",
      "          3       0.65      0.67      0.66       224\n",
      "          4       0.70      0.53      0.60        72\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1762\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.26      0.37        35\n",
      "          1       0.70      0.53      0.60       190\n",
      "          2       0.88      0.95      0.91      1373\n",
      "          3       0.62      0.64      0.63       282\n",
      "          4       0.86      0.25      0.39        76\n",
      "\n",
      "avg / total       0.82      0.83      0.81      1956\n",
      "\n",
      "[1/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.13      0.22        54\n",
      "          1       0.56      0.80      0.66       243\n",
      "          2       0.93      0.89      0.91      1302\n",
      "          3       0.68      0.68      0.68       245\n",
      "          4       0.70      0.68      0.69        76\n",
      "\n",
      "avg / total       0.84      0.82      0.82      1920\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.20      0.32        51\n",
      "          1       0.67      0.63      0.65       212\n",
      "          2       0.88      0.96      0.92      1427\n",
      "          3       0.69      0.63      0.66       303\n",
      "          4       0.74      0.27      0.39        75\n",
      "\n",
      "avg / total       0.82      0.83      0.82      2068\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.20      0.33        50\n",
      "          1       0.60      0.68      0.63       219\n",
      "          2       0.90      0.92      0.91      1287\n",
      "          3       0.70      0.69      0.70       232\n",
      "          4       0.88      0.44      0.58        48\n",
      "\n",
      "avg / total       0.84      0.83      0.83      1836\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.18      0.27        57\n",
      "          1       0.60      0.73      0.66       183\n",
      "          2       0.91      0.93      0.92      1270\n",
      "          3       0.67      0.69      0.68       257\n",
      "          4       0.76      0.29      0.42        75\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1842\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.29      0.41        68\n",
      "          1       0.66      0.57      0.61       211\n",
      "          2       0.89      0.96      0.92      1260\n",
      "          3       0.71      0.66      0.68       212\n",
      "          4       0.80      0.59      0.68        69\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1820\n",
      "\n",
      "[1/30] mean_loss : 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.30      0.41        50\n",
      "          1       0.62      0.64      0.63       188\n",
      "          2       0.91      0.94      0.92      1255\n",
      "          3       0.73      0.71      0.72       253\n",
      "          4       0.75      0.34      0.47        44\n",
      "\n",
      "avg / total       0.84      0.84      0.84      1790\n",
      "\n",
      "[1/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.22      0.33        51\n",
      "          1       0.58      0.65      0.61       164\n",
      "          2       0.88      0.94      0.91      1117\n",
      "          3       0.67      0.63      0.65       287\n",
      "          4       0.78      0.32      0.46        65\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1684\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.20      0.32        44\n",
      "          1       0.71      0.69      0.70       172\n",
      "          2       0.94      0.94      0.94      1300\n",
      "          3       0.66      0.85      0.74       309\n",
      "          4       0.78      0.22      0.34        83\n",
      "\n",
      "avg / total       0.86      0.85      0.84      1908\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.12      0.21        25\n",
      "          1       0.65      0.73      0.69       202\n",
      "          2       0.90      0.94      0.92      1232\n",
      "          3       0.74      0.71      0.73       293\n",
      "          4       0.89      0.38      0.54        86\n",
      "\n",
      "avg / total       0.85      0.85      0.84      1838\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.24        40\n",
      "          1       0.62      0.77      0.69       207\n",
      "          2       0.93      0.91      0.92      1236\n",
      "          3       0.70      0.78      0.74       263\n",
      "          4       0.69      0.31      0.43        58\n",
      "\n",
      "avg / total       0.85      0.84      0.84      1804\n",
      "\n",
      "[1/30] mean_loss : 0.41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.14      0.24        28\n",
      "          1       0.67      0.73      0.70       188\n",
      "          2       0.91      0.95      0.93      1402\n",
      "          3       0.67      0.64      0.66       260\n",
      "          4       0.72      0.35      0.47        80\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1958\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15        36\n",
      "          1       0.61      0.79      0.69       213\n",
      "          2       0.92      0.91      0.92      1262\n",
      "          3       0.68      0.75      0.71       308\n",
      "          4       0.81      0.42      0.55        81\n",
      "\n",
      "avg / total       0.85      0.83      0.83      1900\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.16      0.26        63\n",
      "          1       0.69      0.59      0.63       239\n",
      "          2       0.88      0.97      0.92      1389\n",
      "          3       0.78      0.65      0.71       248\n",
      "          4       0.94      0.43      0.59        35\n",
      "\n",
      "avg / total       0.84      0.85      0.83      1974\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.22      0.35        58\n",
      "          1       0.62      0.73      0.67       211\n",
      "          2       0.89      0.94      0.91      1261\n",
      "          3       0.68      0.58      0.63       229\n",
      "          4       0.81      0.46      0.59        65\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1824\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.21      0.33        43\n",
      "          1       0.65      0.56      0.60       214\n",
      "          2       0.89      0.93      0.91      1383\n",
      "          3       0.66      0.72      0.69       295\n",
      "          4       0.81      0.34      0.48        65\n",
      "\n",
      "avg / total       0.82      0.83      0.82      2000\n",
      "\n",
      "[1/30] mean_loss : 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.17      0.28        36\n",
      "          1       0.63      0.64      0.63       238\n",
      "          2       0.88      0.94      0.91      1380\n",
      "          3       0.76      0.61      0.67       272\n",
      "          4       0.81      0.46      0.59        48\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1974\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.35      0.49        48\n",
      "          1       0.63      0.48      0.54       151\n",
      "          2       0.91      0.95      0.93      1317\n",
      "          3       0.66      0.74      0.70       236\n",
      "          4       0.73      0.38      0.49        64\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1816\n",
      "\n",
      "[1/30] mean_loss : 0.42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        32\n",
      "          1       0.65      0.75      0.70       198\n",
      "          2       0.90      0.94      0.92      1377\n",
      "          3       0.73      0.64      0.68       284\n",
      "          4       0.78      0.27      0.41        51\n",
      "\n",
      "avg / total       0.85      0.85      0.84      1942\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.29      0.41        58\n",
      "          1       0.60      0.77      0.67       216\n",
      "          2       0.94      0.90      0.92      1138\n",
      "          3       0.66      0.78      0.71       241\n",
      "          4       0.88      0.39      0.54        59\n",
      "\n",
      "avg / total       0.84      0.83      0.83      1712\n",
      "\n",
      "[1/30] mean_loss : 0.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.34      0.49        59\n",
      "          1       0.62      0.53      0.57       208\n",
      "          2       0.86      0.97      0.91      1395\n",
      "          3       0.73      0.44      0.55       247\n",
      "          4       0.79      0.39      0.52        49\n",
      "\n",
      "avg / total       0.81      0.82      0.81      1958\n",
      "\n",
      "[1/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.21      0.31        47\n",
      "          1       0.61      0.77      0.68       183\n",
      "          2       0.92      0.92      0.92      1245\n",
      "          3       0.65      0.59      0.62       281\n",
      "          4       0.54      0.58      0.56        98\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1854\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.19      0.30        43\n",
      "          1       0.66      0.72      0.69       213\n",
      "          2       0.90      0.95      0.93      1343\n",
      "          3       0.66      0.65      0.65       310\n",
      "          4       0.86      0.36      0.51       103\n",
      "\n",
      "avg / total       0.83      0.83      0.82      2012\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.41      0.55        74\n",
      "          1       0.66      0.64      0.65       211\n",
      "          2       0.91      0.93      0.92      1404\n",
      "          3       0.64      0.75      0.69       319\n",
      "          4       0.67      0.27      0.38        60\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2068\n",
      "\n",
      "[1/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.15      0.24        40\n",
      "          1       0.62      0.74      0.67       202\n",
      "          2       0.89      0.94      0.91      1105\n",
      "          3       0.70      0.59      0.64       238\n",
      "          4       0.89      0.36      0.51        67\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1652\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.29      0.41        41\n",
      "          1       0.67      0.54      0.59       175\n",
      "          2       0.90      0.95      0.92      1368\n",
      "          3       0.66      0.72      0.69       251\n",
      "          4       0.84      0.30      0.45        69\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1904\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.23      0.31        35\n",
      "          1       0.54      0.69      0.61       117\n",
      "          2       0.93      0.92      0.92      1113\n",
      "          3       0.68      0.72      0.70       279\n",
      "          4       0.68      0.44      0.53        78\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1622\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.23      0.33        39\n",
      "          1       0.62      0.54      0.58       195\n",
      "          2       0.87      0.97      0.92      1351\n",
      "          3       0.73      0.49      0.59       231\n",
      "          4       0.64      0.45      0.53        66\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1882\n",
      "\n",
      "[1/30] mean_loss : 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.08      0.14        38\n",
      "          1       0.64      0.78      0.70       237\n",
      "          2       0.92      0.92      0.92      1075\n",
      "          3       0.65      0.60      0.62       181\n",
      "          4       0.64      0.54      0.58        69\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1600\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.18      0.30        39\n",
      "          1       0.64      0.64      0.64       234\n",
      "          2       0.89      0.93      0.91      1230\n",
      "          3       0.67      0.67      0.67       242\n",
      "          4       0.76      0.36      0.49        53\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1798\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.33      0.45        75\n",
      "          1       0.62      0.65      0.63       241\n",
      "          2       0.91      0.95      0.93      1513\n",
      "          3       0.76      0.76      0.76       285\n",
      "          4       0.81      0.43      0.57        60\n",
      "\n",
      "avg / total       0.85      0.85      0.85      2174\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.14      0.23        43\n",
      "          1       0.58      0.74      0.65       182\n",
      "          2       0.93      0.94      0.93      1234\n",
      "          3       0.71      0.60      0.65       288\n",
      "          4       0.63      0.70      0.66       115\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1862\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.16      0.25        51\n",
      "          1       0.65      0.64      0.65       230\n",
      "          2       0.90      0.95      0.92      1260\n",
      "          3       0.72      0.69      0.70       243\n",
      "          4       0.80      0.32      0.46        50\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1834\n",
      "\n",
      "[1/30] mean_loss : 0.42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.23      0.36        39\n",
      "          1       0.66      0.69      0.67       215\n",
      "          2       0.91      0.95      0.93      1369\n",
      "          3       0.73      0.69      0.71       233\n",
      "          4       0.85      0.45      0.59        38\n",
      "\n",
      "avg / total       0.86      0.86      0.85      1894\n",
      "\n",
      "[1/30] mean_loss : 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.34      0.42        71\n",
      "          1       0.59      0.65      0.61       158\n",
      "          2       0.91      0.94      0.93      1148\n",
      "          3       0.73      0.70      0.71       239\n",
      "          4       0.73      0.56      0.63        66\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1682\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.22      0.33        50\n",
      "          1       0.63      0.69      0.65       216\n",
      "          2       0.89      0.95      0.92      1287\n",
      "          3       0.75      0.59      0.66       241\n",
      "          4       0.74      0.37      0.49        54\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1848\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.56      0.62        86\n",
      "          1       0.63      0.65      0.64       219\n",
      "          2       0.92      0.94      0.93      1284\n",
      "          3       0.72      0.70      0.71       227\n",
      "          4       0.59      0.44      0.51        50\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1866\n",
      "\n",
      "[1/30] mean_loss : 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.45      0.56        20\n",
      "          1       0.69      0.55      0.61       172\n",
      "          2       0.89      0.96      0.92      1238\n",
      "          3       0.70      0.67      0.69       264\n",
      "          4       0.77      0.34      0.47        68\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1762\n",
      "\n",
      "[1/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.20      0.30        49\n",
      "          1       0.62      0.84      0.71       210\n",
      "          2       0.95      0.89      0.92      1217\n",
      "          3       0.60      0.75      0.67       226\n",
      "          4       0.67      0.45      0.54        66\n",
      "\n",
      "avg / total       0.85      0.83      0.83      1768\n",
      "\n",
      "[1/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.16      0.27        32\n",
      "          1       0.66      0.49      0.56       157\n",
      "          2       0.86      0.96      0.91      1387\n",
      "          3       0.69      0.60      0.64       306\n",
      "          4       0.96      0.29      0.45        78\n",
      "\n",
      "avg / total       0.83      0.83      0.81      1960\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.26      0.38        42\n",
      "          1       0.68      0.67      0.68       226\n",
      "          2       0.90      0.94      0.92      1305\n",
      "          3       0.65      0.58      0.62       212\n",
      "          4       0.69      0.54      0.60        71\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1856\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.28      0.39        58\n",
      "          1       0.60      0.67      0.63       174\n",
      "          2       0.92      0.94      0.93      1178\n",
      "          3       0.70      0.74      0.72       236\n",
      "          4       0.71      0.40      0.51        72\n",
      "\n",
      "avg / total       0.84      0.84      0.84      1718\n",
      "\n",
      "[1/30] mean_loss : 0.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.29      0.42        38\n",
      "          1       0.66      0.70      0.68       189\n",
      "          2       0.92      0.92      0.92      1174\n",
      "          3       0.65      0.78      0.71       259\n",
      "          4       0.88      0.32      0.47        66\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1726\n",
      "\n",
      "[1/30] mean_loss : 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.18      0.26        56\n",
      "          1       0.60      0.68      0.64       255\n",
      "          2       0.89      0.94      0.91      1335\n",
      "          3       0.75      0.55      0.63       218\n",
      "          4       0.80      0.66      0.73        50\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1914\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.20      0.30        44\n",
      "          1       0.65      0.66      0.66       188\n",
      "          2       0.90      0.95      0.92      1194\n",
      "          3       0.70      0.61      0.65       225\n",
      "          4       0.67      0.18      0.29        33\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1684\n",
      "\n",
      "[1/30] mean_loss : 0.39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.05      0.09        20\n",
      "          1       0.68      0.65      0.66       157\n",
      "          2       0.92      0.95      0.93      1169\n",
      "          3       0.68      0.71      0.70       205\n",
      "          4       0.74      0.51      0.60        67\n",
      "\n",
      "avg / total       0.85      0.86      0.85      1618\n",
      "\n",
      "[1/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.19      0.29        43\n",
      "          1       0.58      0.76      0.66       238\n",
      "          2       0.93      0.90      0.92      1255\n",
      "          3       0.65      0.67      0.66       208\n",
      "          4       0.67      0.55      0.60        64\n",
      "\n",
      "avg / total       0.84      0.83      0.83      1808\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.25      0.40        32\n",
      "          1       0.74      0.50      0.60       206\n",
      "          2       0.88      0.95      0.91      1304\n",
      "          3       0.63      0.70      0.67       282\n",
      "          4       0.74      0.33      0.45        80\n",
      "\n",
      "avg / total       0.82      0.83      0.81      1904\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.30      0.44        56\n",
      "          1       0.60      0.76      0.67       182\n",
      "          2       0.90      0.93      0.92      1250\n",
      "          3       0.72      0.66      0.69       291\n",
      "          4       0.70      0.39      0.50        67\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1846\n",
      "\n",
      "[1/30] mean_loss : 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.20      0.31        45\n",
      "          1       0.65      0.69      0.67       210\n",
      "          2       0.91      0.92      0.91      1284\n",
      "          3       0.66      0.73      0.69       317\n",
      "          4       0.65      0.55      0.60       100\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1956\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.36      0.48        45\n",
      "          1       0.61      0.72      0.66       171\n",
      "          2       0.90      0.93      0.91      1139\n",
      "          3       0.70      0.70      0.70       295\n",
      "          4       0.73      0.43      0.54        82\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1732\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.37      0.46        49\n",
      "          1       0.62      0.55      0.58       176\n",
      "          2       0.91      0.93      0.92      1296\n",
      "          3       0.66      0.73      0.70       297\n",
      "          4       0.69      0.48      0.56        84\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1902\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.21      0.29        48\n",
      "          1       0.60      0.67      0.63       225\n",
      "          2       0.88      0.94      0.91      1252\n",
      "          3       0.78      0.61      0.69       250\n",
      "          4       0.89      0.53      0.67        77\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1852\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.19      0.29        52\n",
      "          1       0.61      0.69      0.65       169\n",
      "          2       0.92      0.94      0.93      1259\n",
      "          3       0.68      0.67      0.68       217\n",
      "          4       0.71      0.61      0.65        61\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1758\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.23      0.36        43\n",
      "          1       0.66      0.72      0.69       202\n",
      "          2       0.92      0.95      0.93      1254\n",
      "          3       0.75      0.68      0.71       272\n",
      "          4       0.65      0.62      0.64        77\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1848\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.20      0.31        35\n",
      "          1       0.66      0.57      0.61       161\n",
      "          2       0.89      0.95      0.92      1312\n",
      "          3       0.72      0.69      0.70       296\n",
      "          4       0.87      0.26      0.40        50\n",
      "\n",
      "avg / total       0.84      0.85      0.83      1854\n",
      "\n",
      "[1/30] mean_loss : 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.24      0.35        50\n",
      "          1       0.63      0.68      0.65       197\n",
      "          2       0.93      0.92      0.93      1167\n",
      "          3       0.66      0.77      0.71       280\n",
      "          4       0.68      0.48      0.56        88\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1782\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.19      0.31        31\n",
      "          1       0.75      0.66      0.70       219\n",
      "          2       0.88      0.97      0.92      1455\n",
      "          3       0.77      0.53      0.63       283\n",
      "          4       0.60      0.50      0.55        52\n",
      "\n",
      "avg / total       0.84      0.85      0.84      2040\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.25      0.37        56\n",
      "          1       0.57      0.64      0.60       197\n",
      "          2       0.92      0.93      0.92      1312\n",
      "          3       0.67      0.71      0.69       267\n",
      "          4       0.72      0.63      0.67        84\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1916\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.26      0.41        43\n",
      "          1       0.61      0.78      0.68       228\n",
      "          2       0.91      0.92      0.92      1241\n",
      "          3       0.71      0.54      0.61       181\n",
      "          4       0.73      0.59      0.65        41\n",
      "\n",
      "avg / total       0.85      0.84      0.83      1734\n",
      "\n",
      "[1/30] mean_loss : 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.21      0.30        63\n",
      "          1       0.67      0.73      0.70       238\n",
      "          2       0.92      0.95      0.93      1224\n",
      "          3       0.72      0.68      0.70       234\n",
      "          4       0.78      0.70      0.74        99\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1858\n",
      "\n",
      "[1/30] mean_loss : 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.10      0.16        50\n",
      "          1       0.59      0.79      0.68       195\n",
      "          2       0.93      0.90      0.91      1006\n",
      "          3       0.67      0.73      0.70       241\n",
      "          4       0.66      0.35      0.46        54\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1546\n",
      "\n",
      "[1/30] mean_loss : 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.42      0.54        45\n",
      "          1       0.63      0.48      0.55       143\n",
      "          2       0.89      0.97      0.93      1178\n",
      "          3       0.72      0.64      0.68       237\n",
      "          4       0.70      0.35      0.46        55\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1658\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.21      0.32        34\n",
      "          1       0.69      0.61      0.64       180\n",
      "          2       0.90      0.94      0.92      1355\n",
      "          3       0.65      0.68      0.66       281\n",
      "          4       0.75      0.42      0.54        72\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1922\n",
      "\n",
      "[1/30] mean_loss : 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.45      0.49        67\n",
      "          1       0.58      0.67      0.62       191\n",
      "          2       0.90      0.94      0.92      1280\n",
      "          3       0.67      0.56      0.61       254\n",
      "          4       0.76      0.51      0.61        92\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1884\n",
      "\n",
      "[1/30] mean_loss : 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.25      0.36        40\n",
      "          1       0.63      0.71      0.67       252\n",
      "          2       0.91      0.91      0.91      1391\n",
      "          3       0.69      0.67      0.68       249\n",
      "          4       0.63      0.53      0.58        62\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1994\n",
      "\n",
      "[1/30] mean_loss : 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.33      0.45        69\n",
      "          1       0.64      0.70      0.67       224\n",
      "          2       0.91      0.95      0.93      1438\n",
      "          3       0.73      0.68      0.70       239\n",
      "          4       0.70      0.36      0.48        58\n",
      "\n",
      "avg / total       0.85      0.85      0.84      2028\n",
      "\n",
      "[1/30] mean_loss : 0.44\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-af906fde25bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mvalidation_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_transitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                   \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_token_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                  )\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle_review_sentiment/lib/python3.6/site-packages/dlmslib/torch_models/nlp_models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_tokens, train_transitions, train_labels, train_token_labels, epochs, batch_size, validation_tokens, validation_transitions, validation_labels, validation_token_labels)\u001b[0m\n\u001b[1;32m    260\u001b[0m                         \u001b[0mvalidation_transitions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     preds, labels = self._predict_and_pack_tensor(\n\u001b[0;32m--> 262\u001b[0;31m                         \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_transitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_token_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                     )\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle_review_sentiment/lib/python3.6/site-packages/dlmslib/torch_models/nlp_models.py\u001b[0m in \u001b[0;36m_predict_and_pack_tensor\u001b[0;34m(self, batch_tokens, batch_transitions, batch_labels, batch_token_labels)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mbatch_token_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_transitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mpreds_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle_review_sentiment/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle_review_sentiment/lib/python3.6/site-packages/dlmslib/torch_models/nlp_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_index_sequences, transitions)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# shape = (max_len, batch, embed_dims)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mvec_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mpad_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle_review_sentiment/lib/python3.6/site-packages/dlmslib/torch_models/nlp_models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# shape = (max_len, batch, embed_dims)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mvec_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mpad_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle_review_sentiment/lib/python3.6/site-packages/dlmslib/torch_models/nlp_models.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(vec_)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# shape = (max_len, batch, embed_dims)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mvec_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mpad_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_model(train_data[0], train_data[1], train_data[2], train_data[3], \n",
    "                  epochs=30, batch_size=50,\n",
    "                  validation_tokens=dev_data[0], validation_transitions=dev_data[1], \n",
    "                  validation_labels=dev_data[2], validation_token_labels=dev_data[3]\n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
